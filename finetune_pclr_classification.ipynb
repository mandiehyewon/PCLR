{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c1c0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, average_precision_score, f1_score, accuracy_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from scipy import stats\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from hnet import AppendNet\n",
    "\n",
    "def load_pretrained_model(pre_trained_loc=\"./PCLR.h5\") :\n",
    "    pre_trained_model = load_model(pre_trained_loc)\n",
    "    \n",
    "    return pre_trained_model\n",
    "\n",
    "def do_bootstrap(pred_vals, trues, threshold=0.5, n=1000):\n",
    "    auc_list = []\n",
    "    apr_list = []\n",
    "    acc_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    preds = np.array(pred_vals > threshold).astype(int)\n",
    "    \n",
    "    rng = np.random.RandomState(seed=1)\n",
    "    for _ in range(n):\n",
    "        idxs = rng.choice(len(trues), size=len(trues), replace=True)\n",
    "        pred_arr= preds[idxs]\n",
    "        true_arr = trues[idxs]\n",
    "        pred_val_arr = pred_vals[idxs]\n",
    "\n",
    "        auc = roc_auc_score(true_arr, pred_arr)\n",
    "        apr = average_precision_score(true_arr, pred_arr)\n",
    "        acc = accuracy_score(true_arr, pred_val_arr)\n",
    "        f1 = f1_score(true_arr, pred_val_arr)\n",
    "\n",
    "        auc_list.append(auc)\n",
    "        apr_list.append(apr)\n",
    "        acc_list.append(acc)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    return np.array(auc_list), np.array(apr_list), np.array(acc_list), np.array(f1_list)\n",
    "\n",
    "def confidence_interval(values, alpha=0.95):\n",
    "    lower = np.percentile(values, (1-alpha)/2 * 100)\n",
    "    upper = np.percentile(values, (alpha + (1-alpha)/2) * 100)\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "249d61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ecg(df):\n",
    "    ecgs = []\n",
    "    for idx in df.index:\n",
    "        row = df.loc[idx]\n",
    "        qid = row['QuantaID']\n",
    "        doc = row['Date_of_Cath']\n",
    "        fname = f'/storage/shared/apollo/same-day/{qid}_{doc}.csv'\n",
    "        x = pd.read_csv(fname).values[...,1:].astype(np.float32)\n",
    "        x /= 1000\n",
    "        x = x[:4096, :].T\n",
    "        ecgs.append(x)\n",
    "        \n",
    "    ecgs = np.array(ecgs)\n",
    "    return np.transpose(ecgs, (0,2,1))\n",
    "\n",
    "def get_data(batch_size=64):\n",
    "    df_tab = pd.read_csv(os.path.join('/storage/shared/apollo/same-day/tabular_data.csv'))\n",
    "    train_ids = np.load(\"./stores/train_ids.npy\")\n",
    "    val_ids = np.load(\"./stores/val_ids.npy\")\n",
    "    test_ids = np.load(\"./stores/test_ids.npy\")\n",
    "\n",
    "    train_ids = train_ids[len(train_ids) // 2 :]\n",
    "    val_ids = val_ids[len(val_ids) // 2 :]\n",
    "    test_ids = test_ids[len(test_ids) // 2 :]\n",
    "\n",
    "    train_df = df_tab[df_tab[\"QuantaID\"].isin(train_ids)]\n",
    "    val_df = df_tab[df_tab[\"QuantaID\"].isin(val_ids)]\n",
    "    test_df = df_tab[df_tab[\"QuantaID\"].isin(test_ids)]\n",
    "    print(len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "    X_train = get_ecg(train_df)\n",
    "    X_val = get_ecg(val_df)\n",
    "    X_test = get_ecg(test_df)\n",
    "\n",
    "    y_train = (train_df[\"PCWP_mean\"].values >= 18)\n",
    "    y_val = (val_df[\"PCWP_mean\"].values >= 18)\n",
    "    y_test = (test_df[\"PCWP_mean\"].values >= 18)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25647daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "2442 893 923\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_fn = rmse_loss\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0df34dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/storage/araghu/.conda/envs/hfnet/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_3922324/167188699.py\", line 42, in rmse_loss  *\n        return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n\n    TypeError: Value passed to parameter 'x' has DataType bool not in list of allowed values: bfloat16, float16, float32, float64, uint8, int8, uint16, int16, int32, int64, complex64, complex128, uint32, uint64\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m      2\u001b[0m full_model\u001b[38;5;241m.\u001b[39mcompile(optimizer, loss_fn)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mfull_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/araghu/.conda/envs/hfnet/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filevfwb7dyk.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file711qc4x7.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__rmse_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msqrt, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_mean, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msquare, (ag__\u001b[38;5;241m.\u001b[39mld(y_true) \u001b[38;5;241m-\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(y_pred),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/storage/araghu/.conda/envs/hfnet/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_3922324/167188699.py\", line 42, in rmse_loss  *\n        return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n\n    TypeError: Value passed to parameter 'x' has DataType bool not in list of allowed values: bfloat16, float16, float32, float64, uint8, int8, uint16, int16, int32, int64, complex64, complex128, uint32, uint64\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e05d0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = full_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9c402ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./PCLR_finetuned_50epc.pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./PCLR_finetuned_50epc.pb/assets\n"
     ]
    }
   ],
   "source": [
    "full_model.save('./PCLR_finetuned_50epc.pb', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da385cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved tf model\n",
    "loaded_model = tf.keras.models.load_model('./PCLR_finetuned.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab0b27b",
   "metadata": {},
   "source": [
    "# Calculate Classification Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bdda91e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multi_class must be in ('ovo', 'ovr')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m apr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      3\u001b[0m pearson \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m apr \u001b[38;5;241m=\u001b[39m average_precision_score(y_test, y_pred)\n\u001b[1;32m      7\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_true, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred)\n",
      "File \u001b[0;32m/storage/araghu/.conda/envs/hfnet/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:564\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    558\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial AUC computation not available in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass setting, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_fpr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set to `None`, received `max_fpr=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(max_fpr)\n\u001b[1;32m    562\u001b[0m         )\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 564\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_class must be in (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _multiclass_roc_auc_score(\n\u001b[1;32m    566\u001b[0m         y_true, y_score, labels, multi_class, average, sample_weight\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
     ]
    }
   ],
   "source": [
    "auc, apr, acc, f1 = do_bootstrap(y_pred, y_test)\n",
    "print(confidence_interval(auc), confidence_interval(apr), confidence_interval(acc), confidence_interval(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d310710a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
