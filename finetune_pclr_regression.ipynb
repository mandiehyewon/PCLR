{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c1c0097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 00:20:18.004200: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-09 00:20:18.425615: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-09 00:20:19.370436: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/storage/araghu/.conda/envs/hfnet/lib/\n",
      "2023-04-09 00:20:19.370583: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/storage/araghu/.conda/envs/hfnet/lib/\n",
      "2023-04-09 00:20:19.370595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, average_precision_score, f1_score, accuracy_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from scipy import stats\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from hnet import AppendNet\n",
    "\n",
    "def load_pretrained_model(pre_trained_loc=\"./PCLR.h5\") :\n",
    "    pre_trained_model = load_model(pre_trained_loc)\n",
    "    \n",
    "    return pre_trained_model\n",
    "\n",
    "def do_bootstrap_regression(preds, trues, n=1000):\n",
    "    rmse_list = []\n",
    "    r_list = []\n",
    "    pval_list = []\n",
    "\n",
    "    rng = np.random.RandomState(seed=1)\n",
    "    for _ in range(n):\n",
    "        idxs = rng.choice(len(trues), size=len(trues), replace=True)\n",
    "        pred_arr = preds[idxs]\n",
    "        true_arr = trues[idxs]\n",
    "\n",
    "        rmse = rmse_loss(pred_arr, true_arr)\n",
    "        r, pval = stats.pearsonr(true_arr, pred_arr)\n",
    "\n",
    "        rmse_list.append(rmse)\n",
    "        r_list.append(r)\n",
    "        pval_list.append(pval)\n",
    "\n",
    "    return np.array(rmse_list), np.array(r_list), np.array(pval_list)\n",
    "\n",
    "def confidence_interval(values, alpha=0.95):\n",
    "    lower = np.percentile(values, (1-alpha)/2 * 100)\n",
    "    upper = np.percentile(values, (alpha + (1-alpha)/2) * 100)\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "249d61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ecg(df):\n",
    "    ecgs = []\n",
    "    for idx in df.index:\n",
    "        row = df.loc[idx]\n",
    "        qid = row['QuantaID']\n",
    "        doc = row['Date_of_Cath']\n",
    "        fname = f'/storage/shared/apollo/same-day/{qid}_{doc}.csv'\n",
    "        x = pd.read_csv(fname).values[...,1:].astype(np.float32)\n",
    "        x /= 1000\n",
    "        x = x[:4096, :].T\n",
    "        ecgs.append(x)\n",
    "        \n",
    "    ecgs = np.array(ecgs)\n",
    "    return np.transpose(ecgs, (0,2,1))\n",
    "\n",
    "def get_data(batch_size=64):\n",
    "    df_tab = pd.read_csv(os.path.join('/storage/shared/apollo/same-day/tabular_data.csv'))\n",
    "    train_ids = np.load(\"./stores/train_ids.npy\")\n",
    "    val_ids = np.load(\"./stores/val_ids.npy\")\n",
    "    test_ids = np.load(\"./stores/test_ids.npy\")\n",
    "\n",
    "    train_ids = train_ids[len(train_ids) // 2 :]\n",
    "    val_ids = val_ids[len(val_ids) // 2 :]\n",
    "    test_ids = test_ids[len(test_ids) // 2 :]\n",
    "\n",
    "    train_df = df_tab[df_tab[\"QuantaID\"].isin(train_ids)]\n",
    "    val_df = df_tab[df_tab[\"QuantaID\"].isin(val_ids)]\n",
    "    test_df = df_tab[df_tab[\"QuantaID\"].isin(test_ids)]\n",
    "    print(len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "    male_ids = np.load(\"./stores/test_female_ids.npy\")\n",
    "    female_ids = np.load(\"./stores/test_male_ids.npy\")\n",
    "\n",
    "    male_df = df_tab[df_tab[\"QuantaID\"].isin(male_ids)]\n",
    "    female_df = df_tab[df_tab[\"QuantaID\"].isin(female_ids)]\n",
    "    print(len(male_df), len(female_df))\n",
    "        \n",
    "    X_train = get_ecg(train_df)\n",
    "    X_val = get_ecg(val_df)\n",
    "    X_test = get_ecg(test_df)\n",
    "    male_test = get_ecg(male_df)\n",
    "    female_test = get_ecg(female_df)\n",
    "    \n",
    "    y_train = train_df[\"PCWP_mean\"].values\n",
    "    y_val = val_df[\"PCWP_mean\"].values\n",
    "    y_test = test_df[\"PCWP_mean\"].values\n",
    "    y_female = female_df[\"PCWP_mean\"].values\n",
    "    y_male = male_df[\"PCWP_mean\"].values\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, male_test, y_male, female_test, y_female\n",
    "\n",
    "def rmse_loss(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25647daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "2442 893 923\n",
      "1114 711\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=False) # same hidden dimension as dml (128)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_fn = rmse_loss\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, male_test, y_male, female_test, y_female = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0df34dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "77/77 [==============================] - 12s 99ms/step - loss: 15.0063\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.9235\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 11s 147ms/step - loss: 13.7081\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.2645\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.6062\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.4615\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.6717\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.6344\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.0034\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.3835\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.4399\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.2835\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.4502\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.2518\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 11s 138ms/step - loss: 13.3472\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.2949\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.6410\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.3999\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.4393\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.2546\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.9142\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 13.0815\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.3352\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.4429\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.0688\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.4846\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.3973\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.2123\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 11s 142ms/step - loss: 12.8275\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.9884\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.1670\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.1047\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.0361\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.1115\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.3135\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.1893\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.0085\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.3287\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 11s 146ms/step - loss: 12.9859\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.2351\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.2503\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.0607\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.1014\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.9148\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9175\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 12.9721\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.0160\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.8494\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.0769\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.0411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46f85fc790>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d1fbf7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 [==============================] - 12s 98ms/step - loss: 15.5466\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 14.0876\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.7544\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.3075\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.6482\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.4675\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 13.6814\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.6239\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.0276\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 12s 153ms/step - loss: 13.3434\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.4667\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.3233\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.4278\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.3000\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.3789\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.2924\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.6598\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.3597\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.4645\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.3006\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 10s 134ms/step - loss: 12.9523\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.0665\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.3334\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.4333\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.0611\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.5019\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.4934\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 13.2343\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 12.8177\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.9986\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.1478\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.0556\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.0732\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.1311\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.3395\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 13.1394\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.0046\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 10s 135ms/step - loss: 13.3607\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.0111\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.2548\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.2574\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.0958\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.0347\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9225\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.8290\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.0253\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9920\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.8467\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.0914\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.0302\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.1300\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9048\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 10s 131ms/step - loss: 12.8131\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.0348\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.1217\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.1212\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.0153\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.2008\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9011\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.0395\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9264\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.9217\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.8722\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 8s 108ms/step - loss: 13.0827\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.7474\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.0094\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 11s 146ms/step - loss: 13.0309\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.9750\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.9699\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.0543\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.6894\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 9s 111ms/step - loss: 12.9667\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.0114\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.5775\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.8111\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.9127\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.9581\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9111\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.7335\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.8286\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.8650\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.4084\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 11s 143ms/step - loss: 13.2306\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.8510\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.9351\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 12.7872\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.6761\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 13.0014\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 12.7152\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 12.8490\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 12.7734\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.1572\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 12.7508\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.8314\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.9321\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.0483\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 10s 137ms/step - loss: 12.8954\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.7541\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9781\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.9663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46e87e1280>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_fn = rmse_loss\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381c99fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 00:42:14.698153: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-04-09 00:42:16.868245: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-09 00:42:16.870428: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-09 00:42:16.870504: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-04-09 00:42:16.873389: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-09 00:42:16.873946: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 17s 86ms/step - loss: 15.2831\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 13.9908\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 13.7485\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 13.3453\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 6s 72ms/step - loss: 13.6345\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 6s 72ms/step - loss: 13.4960\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 13.6513\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 13.6370\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 13.0293\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 13.3668\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 4s 48ms/step - loss: 13.4074\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 13.2576\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 13.4606\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 13.3014\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 13.3778\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 13.2739\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 13.6519\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 13.3876\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 13.4312\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 13.3122\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 5s 67ms/step - loss: 12.8893\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 13.0292\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 13.3744\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 5s 66ms/step - loss: 13.4102\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 13.0514\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 13.5193\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 13.4147\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 13.2157\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.7662\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 12.9640\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 13.1064\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 6s 72ms/step - loss: 13.0479\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 13.0713\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 13.1430\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 13.3464\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 13.1705\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 13.0729\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 13.3303\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 12.9714\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 4s 49ms/step - loss: 13.2753\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 4s 47ms/step - loss: 13.2460\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 13.0649\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 13.0842\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 12.9572\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 12.9209\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 12.9839\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 13.0153\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 12.8148\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 13.0830\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 5s 66ms/step - loss: 12.9369\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 13.1314\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 12.8994\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 12.8017\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 4s 49ms/step - loss: 12.9956\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 13.0064\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 4s 49ms/step - loss: 13.1022\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 13.0165\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 13.2108\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.8716\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 13.0338\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 12.8791\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 12.9571\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 12.8791\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 13.1602\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 12.7696\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 13.0160\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 13.0151\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 12.9344\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 12.9907\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 5s 66ms/step - loss: 13.0148\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 5s 63ms/step - loss: 12.6204\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 12.9276\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 13.0300\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 12.5036\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 5s 66ms/step - loss: 12.8304\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 5s 62ms/step - loss: 12.9693\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 12.9961\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 12.9614\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.6908\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 12.8356\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 12.8251\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 12.4027\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 13.2467\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 5s 66ms/step - loss: 12.8687\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.9408\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 5s 66ms/step - loss: 12.8041\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 6s 72ms/step - loss: 12.6829\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 13.0218\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 5s 64ms/step - loss: 12.6864\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 12.8275\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 12.7875\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 5s 67ms/step - loss: 13.1303\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 5s 62ms/step - loss: 12.7295\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 12.8471\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 12.9185\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 4s 49ms/step - loss: 13.0611\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 12.9162\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.7303\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 5s 67ms/step - loss: 12.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 12.9233\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.8503\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 12.6220\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 12.9161\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 12.8678\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 13.0156\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.4732\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 12.7896\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 4s 49ms/step - loss: 12.6068\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 4s 49ms/step - loss: 12.8019\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 4s 49ms/step - loss: 12.7599\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.7275\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 12.6919\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.7334\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.9755\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.5545\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.6803\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.7756\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.9315\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 12.8094\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 12.5880\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 12.5147\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 12.7117\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 12.7093\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 13.0090\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 12.7694\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.7004\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 12.7640\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 12.5567\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 12.7082\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.5825\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.6528\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.8583\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.6449\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 13.0238\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 12.7373\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 4s 49ms/step - loss: 12.6397\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 12.6213\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.6913\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 12.8559\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.4428\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.6523\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 12.6512\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 12.6543\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 12.8594\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 5s 66ms/step - loss: 12.6895\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 12.5510\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 12.4785\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 12.7588\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 12.6333\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 6s 71ms/step - loss: 12.5054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda4845c5b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 150\n",
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "loss_fn = rmse_loss\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c06f23cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/175\n",
      "77/77 [==============================] - 13s 94ms/step - loss: 16.1545\n",
      "Epoch 2/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 14.0904\n",
      "Epoch 3/175\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.7653\n",
      "Epoch 4/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.3809\n",
      "Epoch 5/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.6664\n",
      "Epoch 6/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.5445\n",
      "Epoch 7/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.6168\n",
      "Epoch 8/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.7027\n",
      "Epoch 9/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.9921\n",
      "Epoch 10/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.2832\n",
      "Epoch 11/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.4776\n",
      "Epoch 12/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.3266\n",
      "Epoch 13/175\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.4564\n",
      "Epoch 14/175\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.3205\n",
      "Epoch 15/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.3453\n",
      "Epoch 16/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 13.2868\n",
      "Epoch 17/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 13.6519\n",
      "Epoch 18/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.4074\n",
      "Epoch 19/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.4700\n",
      "Epoch 20/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.2912\n",
      "Epoch 21/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.9698\n",
      "Epoch 22/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.0963\n",
      "Epoch 23/175\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 13.4165\n",
      "Epoch 24/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.4751\n",
      "Epoch 25/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.0903\n",
      "Epoch 26/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.4995\n",
      "Epoch 27/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.4770\n",
      "Epoch 28/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.2130\n",
      "Epoch 29/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.8291\n",
      "Epoch 30/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.0240\n",
      "Epoch 31/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.1747\n",
      "Epoch 32/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0888\n",
      "Epoch 33/175\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.0905\n",
      "Epoch 34/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.1352\n",
      "Epoch 35/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.3141\n",
      "Epoch 36/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.1479\n",
      "Epoch 37/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0953\n",
      "Epoch 38/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.3534\n",
      "Epoch 39/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0202\n",
      "Epoch 40/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.2741\n",
      "Epoch 41/175\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.2980\n",
      "Epoch 42/175\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.0920\n",
      "Epoch 43/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.0357\n",
      "Epoch 44/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9858\n",
      "Epoch 45/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9131\n",
      "Epoch 46/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9808\n",
      "Epoch 47/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.9993\n",
      "Epoch 48/175\n",
      "77/77 [==============================] - 9s 123ms/step - loss: 12.8401\n",
      "Epoch 49/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.1428\n",
      "Epoch 50/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0731\n",
      "Epoch 51/175\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.1743\n",
      "Epoch 52/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9502\n",
      "Epoch 53/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.8337\n",
      "Epoch 54/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.0553\n",
      "Epoch 55/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0785\n",
      "Epoch 56/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.1001\n",
      "Epoch 57/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0525\n",
      "Epoch 58/175\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.2862\n",
      "Epoch 59/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.9386\n",
      "Epoch 60/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0946\n",
      "Epoch 61/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.9502\n",
      "Epoch 62/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.9589\n",
      "Epoch 63/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9129\n",
      "Epoch 64/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.1524\n",
      "Epoch 65/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.7962\n",
      "Epoch 66/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0178\n",
      "Epoch 67/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.0106\n",
      "Epoch 68/175\n",
      "77/77 [==============================] - 9s 120ms/step - loss: 12.9713\n",
      "Epoch 69/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.0428\n",
      "Epoch 70/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.0344\n",
      "Epoch 71/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6942\n",
      "Epoch 72/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.9666\n",
      "Epoch 73/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.0589\n",
      "Epoch 74/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.5485\n",
      "Epoch 75/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8626\n",
      "Epoch 76/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.9690\n",
      "Epoch 77/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.0182\n",
      "Epoch 78/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.9330\n",
      "Epoch 79/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.7206\n",
      "Epoch 80/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8592\n",
      "Epoch 81/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8884\n",
      "Epoch 82/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.4809\n",
      "Epoch 83/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.2205\n",
      "Epoch 84/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8679\n",
      "Epoch 85/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.9662\n",
      "Epoch 86/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.8373\n",
      "Epoch 87/175\n",
      "77/77 [==============================] - 10s 129ms/step - loss: 12.6974\n",
      "Epoch 88/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.0401\n",
      "Epoch 89/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7640\n",
      "Epoch 90/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.8577\n",
      "Epoch 91/175\n",
      "77/77 [==============================] - 8s 97ms/step - loss: 12.7883\n",
      "Epoch 92/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.1476\n",
      "Epoch 93/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.7597\n",
      "Epoch 94/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.8784\n",
      "Epoch 95/175\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 12.9377\n",
      "Epoch 96/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 13.0894\n",
      "Epoch 97/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.9349\n",
      "Epoch 98/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.7920\n",
      "Epoch 99/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.9776\n",
      "Epoch 100/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.9635\n",
      "Epoch 101/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.8726\n",
      "Epoch 102/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.6349\n",
      "Epoch 103/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.9229\n",
      "Epoch 104/175\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 12.8846\n",
      "Epoch 105/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 13.0523\n",
      "Epoch 106/175\n",
      "77/77 [==============================] - 10s 127ms/step - loss: 12.4805\n",
      "Epoch 107/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.7710\n",
      "Epoch 108/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.6550\n",
      "Epoch 109/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.8191\n",
      "Epoch 110/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.8127\n",
      "Epoch 111/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.8041\n",
      "Epoch 112/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6944\n",
      "Epoch 113/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.7308\n",
      "Epoch 114/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.9677\n",
      "Epoch 115/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6033\n",
      "Epoch 116/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7483\n",
      "Epoch 117/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8269\n",
      "Epoch 118/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.9241\n",
      "Epoch 119/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.8321\n",
      "Epoch 120/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.6180\n",
      "Epoch 121/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.5440\n",
      "Epoch 122/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.7066\n",
      "Epoch 123/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.6891\n",
      "Epoch 124/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.0529\n",
      "Epoch 125/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.8051\n",
      "Epoch 126/175\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 12.7273\n",
      "Epoch 127/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8111\n",
      "Epoch 128/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.5792\n",
      "Epoch 129/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7454\n",
      "Epoch 130/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.6131\n",
      "Epoch 131/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.6963\n",
      "Epoch 132/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8583\n",
      "Epoch 133/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.6237\n",
      "Epoch 134/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.0550\n",
      "Epoch 135/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.7295\n",
      "Epoch 136/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.6868\n",
      "Epoch 137/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.6610\n",
      "Epoch 138/175\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7352\n",
      "Epoch 139/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8705\n",
      "Epoch 140/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.4648\n",
      "Epoch 141/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.6541\n",
      "Epoch 142/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6716\n",
      "Epoch 143/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.6658\n",
      "Epoch 144/175\n",
      "77/77 [==============================] - 9s 123ms/step - loss: 12.8718\n",
      "Epoch 145/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.7351\n",
      "Epoch 146/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.5699\n",
      "Epoch 147/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.4671\n",
      "Epoch 148/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.7477\n",
      "Epoch 149/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.6263\n",
      "Epoch 150/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.5374\n",
      "Epoch 151/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.8668\n",
      "Epoch 152/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.7645\n",
      "Epoch 153/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.4571\n",
      "Epoch 154/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.8152\n",
      "Epoch 155/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.7171\n",
      "Epoch 156/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.4742\n",
      "Epoch 157/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.4262\n",
      "Epoch 158/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.7445\n",
      "Epoch 159/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.7479\n",
      "Epoch 160/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.8191\n",
      "Epoch 161/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.7439\n",
      "Epoch 162/175\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.5923\n",
      "Epoch 163/175\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 12.7181\n",
      "Epoch 164/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7932\n",
      "Epoch 165/175\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.5161\n",
      "Epoch 166/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.6323\n",
      "Epoch 167/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.6732\n",
      "Epoch 168/175\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 12.9052\n",
      "Epoch 169/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.5111\n",
      "Epoch 170/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.5986\n",
      "Epoch 171/175\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.3877\n",
      "Epoch 172/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.8369\n",
      "Epoch 173/175\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 12.3939\n",
      "Epoch 174/175\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.7046\n",
      "Epoch 175/175\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.6367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f464c429910>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 175\n",
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_fn = rmse_loss\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "055fb4af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "77/77 [==============================] - 12s 96ms/step - loss: 15.4870\n",
      "Epoch 2/200\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 14.0569\n",
      "Epoch 3/200\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.7952\n",
      "Epoch 4/200\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 13.4087\n",
      "Epoch 5/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.6161\n",
      "Epoch 6/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.4954\n",
      "Epoch 7/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.7052\n",
      "Epoch 8/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.6811\n",
      "Epoch 9/200\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 13.0129\n",
      "Epoch 10/200\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.3911\n",
      "Epoch 11/200\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 13.3794\n",
      "Epoch 12/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.3289\n",
      "Epoch 13/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.4802\n",
      "Epoch 14/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.2848\n",
      "Epoch 15/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.3875\n",
      "Epoch 16/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.3004\n",
      "Epoch 17/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.7036\n",
      "Epoch 18/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.4042\n",
      "Epoch 19/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.4962\n",
      "Epoch 20/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.3079\n",
      "Epoch 21/200\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.9459\n",
      "Epoch 22/200\n",
      "77/77 [==============================] - 10s 128ms/step - loss: 13.1211\n",
      "Epoch 23/200\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 13.4162\n",
      "Epoch 24/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.4433\n",
      "Epoch 25/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.1422\n",
      "Epoch 26/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.5124\n",
      "Epoch 27/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.4356\n",
      "Epoch 28/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.1945\n",
      "Epoch 29/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.7928\n",
      "Epoch 30/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.9999\n",
      "Epoch 31/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.1575\n",
      "Epoch 32/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.0602\n",
      "Epoch 33/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.0943\n",
      "Epoch 34/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.1497\n",
      "Epoch 35/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 13.3609\n",
      "Epoch 36/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.2005\n",
      "Epoch 37/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 13.0758\n",
      "Epoch 38/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.4120\n",
      "Epoch 39/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9601\n",
      "Epoch 40/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.2457\n",
      "Epoch 41/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.2970\n",
      "Epoch 42/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0692\n",
      "Epoch 43/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.1343\n",
      "Epoch 44/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.9416\n",
      "Epoch 45/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8771\n",
      "Epoch 46/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.0310\n",
      "Epoch 47/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9918\n",
      "Epoch 48/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.7866\n",
      "Epoch 49/200\n",
      "77/77 [==============================] - 9s 119ms/step - loss: 13.1403\n",
      "Epoch 50/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0287\n",
      "Epoch 51/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.1586\n",
      "Epoch 52/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9427\n",
      "Epoch 53/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8172\n",
      "Epoch 54/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.0049\n",
      "Epoch 55/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.0670\n",
      "Epoch 56/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.1201\n",
      "Epoch 57/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0412\n",
      "Epoch 58/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.2535\n",
      "Epoch 59/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8725\n",
      "Epoch 60/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.0727\n",
      "Epoch 61/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9196\n",
      "Epoch 62/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9559\n",
      "Epoch 63/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8804\n",
      "Epoch 64/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.1668\n",
      "Epoch 65/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.7547\n",
      "Epoch 66/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9784\n",
      "Epoch 67/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9873\n",
      "Epoch 68/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.9601\n",
      "Epoch 69/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9760\n",
      "Epoch 70/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0594\n",
      "Epoch 71/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.6572\n",
      "Epoch 72/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9517\n",
      "Epoch 73/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0102\n",
      "Epoch 74/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.5131\n",
      "Epoch 75/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8390\n",
      "Epoch 76/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9651\n",
      "Epoch 77/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9781\n",
      "Epoch 78/200\n",
      "77/77 [==============================] - 9s 117ms/step - loss: 12.9379\n",
      "Epoch 79/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.6849\n",
      "Epoch 80/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8414\n",
      "Epoch 81/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8588\n",
      "Epoch 82/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.4306\n",
      "Epoch 83/200\n",
      "77/77 [==============================] - 7s 90ms/step - loss: 13.2156\n",
      "Epoch 84/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.8267\n",
      "Epoch 85/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9625\n",
      "Epoch 86/200\n",
      "77/77 [==============================] - 7s 90ms/step - loss: 12.8378\n",
      "Epoch 87/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.6850\n",
      "Epoch 88/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0047\n",
      "Epoch 89/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.7194\n",
      "Epoch 90/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8682\n",
      "Epoch 91/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.7840\n",
      "Epoch 92/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.1368\n",
      "Epoch 93/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.7358\n",
      "Epoch 94/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8426\n",
      "Epoch 95/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.9060\n",
      "Epoch 96/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 13.0470\n",
      "Epoch 97/200\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.8951\n",
      "Epoch 98/200\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.7654\n",
      "Epoch 99/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9758\n",
      "Epoch 100/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9770\n",
      "Epoch 101/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8791\n",
      "Epoch 102/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.6094\n",
      "Epoch 103/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.9395\n",
      "Epoch 104/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8842\n",
      "Epoch 105/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.0374\n",
      "Epoch 106/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.4947\n",
      "Epoch 107/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.7363\n",
      "Epoch 108/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6492\n",
      "Epoch 109/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8198\n",
      "Epoch 110/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7683\n",
      "Epoch 111/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.7720\n",
      "Epoch 112/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.6930\n",
      "Epoch 113/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.7725\n",
      "Epoch 114/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.9692\n",
      "Epoch 115/200\n",
      "77/77 [==============================] - 9s 116ms/step - loss: 12.5883\n",
      "Epoch 116/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.7622\n",
      "Epoch 117/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8186\n",
      "Epoch 118/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.9060\n",
      "Epoch 119/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8580\n",
      "Epoch 120/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.6160\n",
      "Epoch 121/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.5405\n",
      "Epoch 122/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.7475\n",
      "Epoch 123/200\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.6802\n",
      "Epoch 124/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.0577\n",
      "Epoch 125/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.7921\n",
      "Epoch 126/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.6996\n",
      "Epoch 127/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7660\n",
      "Epoch 128/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.5614\n",
      "Epoch 129/200\n",
      "77/77 [==============================] - 9s 123ms/step - loss: 12.7214\n",
      "Epoch 130/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.5599\n",
      "Epoch 131/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6634\n",
      "Epoch 132/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8627\n",
      "Epoch 133/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.6401\n",
      "Epoch 134/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.0234\n",
      "Epoch 135/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7089\n",
      "Epoch 136/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6448\n",
      "Epoch 137/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6294\n",
      "Epoch 138/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6773\n",
      "Epoch 139/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.8831\n",
      "Epoch 140/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.4486\n",
      "Epoch 141/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.6121\n",
      "Epoch 142/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6759\n",
      "Epoch 143/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.6474\n",
      "Epoch 144/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8610\n",
      "Epoch 145/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.7192\n",
      "Epoch 146/200\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 12.5586\n",
      "Epoch 147/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.4675\n",
      "Epoch 148/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7521\n",
      "Epoch 149/200\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.6352\n",
      "Epoch 150/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.5351\n",
      "Epoch 151/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.8531\n",
      "Epoch 152/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.7473\n",
      "Epoch 153/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.4323\n",
      "Epoch 154/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7714\n",
      "Epoch 155/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7090\n",
      "Epoch 156/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.4789\n",
      "Epoch 157/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.3916\n",
      "Epoch 158/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7708\n",
      "Epoch 159/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7267\n",
      "Epoch 160/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8058\n",
      "Epoch 161/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7527\n",
      "Epoch 162/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.5904\n",
      "Epoch 163/200\n",
      "77/77 [==============================] - 10s 127ms/step - loss: 12.6747\n",
      "Epoch 164/200\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 12.7604\n",
      "Epoch 165/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.4962\n",
      "Epoch 166/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.6584\n",
      "Epoch 167/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6896\n",
      "Epoch 168/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8841\n",
      "Epoch 169/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.5054\n",
      "Epoch 170/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.5989\n",
      "Epoch 171/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.4027\n",
      "Epoch 172/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7673\n",
      "Epoch 173/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.3631\n",
      "Epoch 174/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.7012\n",
      "Epoch 175/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.6382\n",
      "Epoch 176/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.5501\n",
      "Epoch 177/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.7535\n",
      "Epoch 178/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.5853\n",
      "Epoch 179/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8043\n",
      "Epoch 180/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7148\n",
      "Epoch 181/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.4380\n",
      "Epoch 182/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7133\n",
      "Epoch 183/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7989\n",
      "Epoch 184/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8678\n",
      "Epoch 185/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6370\n",
      "Epoch 186/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.5390\n",
      "Epoch 187/200\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 12.6816\n",
      "Epoch 188/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6826\n",
      "Epoch 189/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.3242\n",
      "Epoch 190/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.4614\n",
      "Epoch 191/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.6179\n",
      "Epoch 192/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8486\n",
      "Epoch 193/200\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 12.3652\n",
      "Epoch 194/200\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.3647\n",
      "Epoch 195/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.5636\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 7s 92ms/step - loss: 12.5300\n",
      "Epoch 197/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.2884\n",
      "Epoch 198/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.6437\n",
      "Epoch 199/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.5554\n",
      "Epoch 200/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.6519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46f86c9640>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 200\n",
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_fn = rmse_loss\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "654a8166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Getting prediction result from test set\n",
    "'''\n",
    "y_pred = full_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9c402ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./PCLR_finetuned_100epc.pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./PCLR_finetuned_100epc.pb/assets\n"
     ]
    }
   ],
   "source": [
    "full_model.save('./PCLR_finetuned_100epc.pb', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da385cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved tf model\n",
    "loaded_model = tf.keras.models.load_model('./PCLR_finetuned.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab0b27b",
   "metadata": {},
   "source": [
    "# Calculate Classification Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d07769dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(11.718298284532933, shape=(), dtype=float64)\n",
      "0.5179734023757416 1.7000212654359237e-64\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "r, pval = stats.pearsonr(y_test, np.concatenate(y_pred))\n",
    "print(rmse_loss(y_test, y_pred))\n",
    "print(r, pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "623d3acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.662241673856977 0.5168803322877793 3.885793744767385e-48\n",
      "(10.168321327256356, 11.186809058909072) (0.46935757473184414, 0.5653645253170076) (4.403350490234938e-79, 9.551261205355765e-52)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "50 epoch model\n",
    "'''\n",
    "rmse, r, pval = do_bootstrap_regression(np.concatenate(y_pred), y_test)\n",
    "print(rmse.mean(), r.mean(), pval.mean())\n",
    "print(confidence_interval(rmse), confidence_interval(r), confidence_interval(pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ecb6653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.08667670973824 0.5084383288648698 5.124600599466284e-44\n",
      "(9.593113688193553, 10.608999002632787) (0.4534978599475333, 0.5592618550246696) (4.559193565980286e-77, 5.1785051956098e-48)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "100 epoch model\n",
    "'''\n",
    "rmse, r, pval = do_bootstrap_regression(np.concatenate(y_pred), y_test)\n",
    "print(rmse.mean(), r.mean(), pval.mean())\n",
    "print(confidence_interval(rmse), confidence_interval(r), confidence_interval(pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4ea977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.848489722993618 0.46944465590783035 3.0449579264607663e-35\n",
      "(9.338509122190928, 10.366695124278358) (0.4179658931128352, 0.5250832141152932) (1.53915223843851e-66, 2.4962666858646983e-40)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "150 epoch model\n",
    "'''\n",
    "rmse, r, pval = do_bootstrap_regression(np.concatenate(y_pred), y_test)\n",
    "print(rmse.mean(), r.mean(), pval.mean())\n",
    "print(confidence_interval(rmse), confidence_interval(r), confidence_interval(pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "940e70e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.850863609684545 0.49767297670143773 5.444660867408191e-43\n",
      "(9.35858689961837, 10.36080203660364) (0.44836077927932255, 0.5494779474730525) (6.255070185093435e-74, 7.624212698991938e-47)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "175 epoch model\n",
    "'''\n",
    "rmse, r, pval = do_bootstrap_regression(np.concatenate(y_pred), y_test)\n",
    "print(rmse.mean(), r.mean(), pval.mean())\n",
    "print(confidence_interval(rmse), confidence_interval(r), confidence_interval(pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01ccda36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.292663228474936 0.47730382296197216 2.970788508126865e-37\n",
      "(9.783613390282376, 10.830710205153133) (0.42562339353459316, 0.5319061016216475) (1.5150117569838069e-68, 6.574814400434942e-42)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "200 epoch model\n",
    "'''\n",
    "rmse, r, pval = do_bootstrap_regression(np.concatenate(y_pred), y_test)\n",
    "print(rmse.mean(), r.mean(), pval.mean())\n",
    "print(confidence_interval(rmse), confidence_interval(r), confidence_interval(pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a52d35",
   "metadata": {},
   "source": [
    "# Subgroup Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3fecec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 15ms/step\n",
      "10.039471949439573 0.484278478554083 4.902644094954473e-40\n",
      "(9.525350752320579, 10.568466900038379) (0.43473973384124037, 0.5391527787121098) (9.961575265424734e-71, 7.704279890631517e-44)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "150 epoch model\n",
    "'''\n",
    "y_pred = full_model.predict(X_test)\n",
    "rmse, r, pval = do_bootstrap_regression(np.concatenate(y_pred), y_test)\n",
    "print(rmse.mean(), r.mean(), pval.mean())\n",
    "print(confidence_interval(rmse), confidence_interval(r), confidence_interval(pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28fbcda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 20ms/step\n",
      "11.138536381121034 0.5375720048181512 2.588236043433157e-62\n",
      "(10.667693263920379, 11.60368216416663) (0.49158370952901476, 0.5835548220252381) (1.2198080590473877e-102, 7.817113498207257e-69)\n"
     ]
    }
   ],
   "source": [
    "male_pred = full_model.predict(male_test)\n",
    "rmse_male, r_male, pval_male = do_bootstrap_regression(male_pred, y_male)\n",
    "print(rmse_male.mean(), r_male.mean(), pval_male.mean())\n",
    "print(confidence_interval(rmse_male), confidence_interval(r_male), confidence_interval(pval_male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cb2d1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 48ms/step\n",
      "11.632920180842552 0.4567063803872219 2.592465179744597e-24\n",
      "(10.960079965417428, 12.304295703102092) (0.395897170005528, 0.516874417736068) (8.079708423410909e-50, 4.265781643675823e-28)\n"
     ]
    }
   ],
   "source": [
    "female_pred = full_model.predict(female_test)\n",
    "rmse_female, r_female, pval_female = do_bootstrap_regression(female_pred, y_female)\n",
    "print(rmse_female.mean(), r_female.mean(), pval_female.mean())\n",
    "print(confidence_interval(rmse_female), confidence_interval(r_female), confidence_interval(pval_female))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5c5003f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis test:\n",
      "  Statistic: 854.8728237721143\n",
      "  p-value: 6.341729505804985e-188\n",
      "\n",
      "Independent t-test:\n",
      "  Statistic: -36.85698456210658\n",
      "  p-value: 2.45423091570506e-227\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Kruskal-Wallis test\n",
    "kruskal_stat, kruskal_p_value = stats.kruskal(rmse_male, rmse_female)\n",
    "print(\"Kruskal-Wallis test:\")\n",
    "print(\"  Statistic:\", kruskal_stat)\n",
    "print(\"  p-value:\", kruskal_p_value)\n",
    "\n",
    "# Independent t-test\n",
    "t_stat, t_p_value = stats.ttest_ind(rmse_male, rmse_female)\n",
    "print(\"\\nIndependent t-test:\")\n",
    "print(\"  Statistic:\", t_stat)\n",
    "print(\"  p-value:\", t_p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a6c72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/rmse.npy', rmse)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/rmse_male.npy',rmse_male)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/rmse_female.npy',rmse_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd74906f",
   "metadata": {},
   "source": [
    "# Trend Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "756dbc66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 1s 523ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 469ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "dir_root = '/storage/hyewonjeong/metricssl_02'\n",
    "dir_result = '/storage/hyewonjeong/metricssl_02/result'\n",
    "dir_trend = '/storage/hyewonjeong/metricssl_02/trend_fig'\n",
    "\n",
    "df_tab = pd.read_csv('/storage/shared/apollo/same-day/tabular_data.csv')\n",
    "trend_ids = np.load(os.path.join(dir_root, '/storage/hyewonjeong/metricssl_02/stores/trend_testid.npy'))\n",
    "\n",
    "# Extract rows from tabular_data.csv that correspond to the trend IDs\n",
    "trend_df = df_tab[df_tab[\"QuantaID\"].isin(trend_ids)]\n",
    "\n",
    "# Iterate over the trend IDs and plot the predicted and actual values of PCWP_mean\n",
    "for trend_id in trend_ids:\n",
    "    # Get rows from tabular_data.csv that correspond to the current trend ID\n",
    "    trend_rows = trend_df[trend_df[\"QuantaID\"] == trend_id]\n",
    "    \n",
    "    # Sort the rows by the catheterization date\n",
    "    trend_rows = trend_rows.sort_values(by=\"Date_of_Cath\")\n",
    "    \n",
    "    # Get the PCWP_mean values and catheterization dates\n",
    "    pcwp_means = trend_rows[\"PCWP_mean\"].values\n",
    "    cath_dates = pd.to_datetime(trend_rows[\"Date_of_Cath\"]).dt.date\n",
    "    \n",
    "    # Compute the predicted values of PCWP_mean using the supervised DML model\n",
    "    features = trend_rows.drop([\"QuantaID\", \"Date_of_Cath\", \"PCWP_mean\"], axis=1).values\n",
    "    ecgs = get_ecg(trend_rows)\n",
    "    pclr_pred = full_model.predict(ecgs)\n",
    "    np.save(os.path.join(dir_trend, 'pclr_{}'.format(str(trend_id))), pclr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89fdcdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_pred = np.load('/storage/hyewonjeong/metricssl_02/trend_fig/pclr_1647084.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8e6d743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.0870132],\n",
       "       [7.3210917],\n",
       "       [6.219167 ],\n",
       "       [5.883561 ],\n",
       "       [5.8503976],\n",
       "       [7.1804   ],\n",
       "       [7.3934503],\n",
       "       [8.690815 ],\n",
       "       [7.4013486]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "712f5ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the predicted and actual values of PCWP_mean\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(cath_dates, pcwp_means, label=\"Ground Truth\")\n",
    "ax.plot(cath_dates, pclr_pred, label=\"PCLR\")\n",
    "ax.set_xlabel(\"Date of Catheterization\")\n",
    "ax.set_ylabel(\"PCWP\")\n",
    "ax.set_title(f\"Trend ID {trend_id}\")\n",
    "ax.legend()\n",
    "plt.savefig(os.path.join(dir_trend, f\"trend_{trend_id}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788899f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
