{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c1c0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, average_precision_score, f1_score, accuracy_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from scipy import stats\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from hnet import AppendNet\n",
    "\n",
    "def load_pretrained_model(pre_trained_loc=\"./PCLR.h5\") :\n",
    "    pre_trained_model = load_model(pre_trained_loc)\n",
    "    \n",
    "    return pre_trained_model\n",
    "\n",
    "def do_bootstrap_regression(preds, trues, n=1000):\n",
    "    rmse_list = []\n",
    "    r_list = []\n",
    "    pval_list = []\n",
    "\n",
    "    rng = np.random.RandomState(seed=1)\n",
    "    for _ in range(n):\n",
    "        idxs = rng.choice(len(trues), size=len(trues), replace=True)\n",
    "        pred_arr = preds[idxs]\n",
    "        true_arr = trues[idxs]\n",
    "\n",
    "        rmse = rmse_loss(pred_arr, true_arr)\n",
    "        r, pval = stats.pearsonr(true_arr, pred_arr)\n",
    "\n",
    "        rmse_list.append(rmse)\n",
    "        r_list.append(r)\n",
    "        pval_list.append(pval)\n",
    "\n",
    "    return np.array(rmse_list), np.array(r_list), np.array(pval_list)\n",
    "\n",
    "def confidence_interval(values, alpha=0.95):\n",
    "    lower = np.percentile(values, (1-alpha)/2 * 100)\n",
    "    upper = np.percentile(values, (alpha + (1-alpha)/2) * 100)\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "249d61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ecg(df):\n",
    "    ecgs = []\n",
    "    for idx in df.index:\n",
    "        row = df.loc[idx]\n",
    "        qid = row['QuantaID']\n",
    "        doc = row['Date_of_Cath']\n",
    "        fname = f'/storage/shared/apollo/same-day/{qid}_{doc}.csv'\n",
    "        x = pd.read_csv(fname).values[...,1:].astype(np.float32)\n",
    "        x /= 1000\n",
    "        x = x[:4096, :].T\n",
    "        ecgs.append(x)\n",
    "        \n",
    "    ecgs = np.array(ecgs)\n",
    "    return np.transpose(ecgs, (0,2,1))\n",
    "\n",
    "def get_data(batch_size=64):\n",
    "    df_tab = pd.read_csv(os.path.join('/storage/shared/apollo/same-day/tabular_data.csv'))\n",
    "    train_ids = np.load(\"./stores/train_ids.npy\")\n",
    "    val_ids = np.load(\"./stores/val_ids.npy\")\n",
    "    test_ids = np.load(\"./stores/test_ids.npy\")\n",
    "\n",
    "    train_ids = train_ids[len(train_ids) // 2 :]\n",
    "    val_ids = val_ids[len(val_ids) // 2 :]\n",
    "    test_ids = test_ids[len(test_ids) // 2 :]\n",
    "\n",
    "    train_df = df_tab[df_tab[\"QuantaID\"].isin(train_ids)]\n",
    "    val_df = df_tab[df_tab[\"QuantaID\"].isin(val_ids)]\n",
    "    test_df = df_tab[df_tab[\"QuantaID\"].isin(test_ids)]\n",
    "    print(len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "    X_train = get_ecg(train_df)\n",
    "    X_val = get_ecg(val_df)\n",
    "    X_test = get_ecg(test_df)\n",
    "\n",
    "    y_train = train_df[\"PCWP_mean\"].values\n",
    "    y_val = val_df[\"PCWP_mean\"].values\n",
    "    y_test = test_df[\"PCWP_mean\"].values\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "def rmse_loss(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "25647daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2442 893 923\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=False) # same hidden dimension as dml (128)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_fn = rmse_loss\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0df34dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "77/77 [==============================] - 12s 99ms/step - loss: 15.0063\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.9235\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 11s 147ms/step - loss: 13.7081\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.2645\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.6062\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.4615\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.6717\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.6344\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.0034\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.3835\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.4399\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.2835\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.4502\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.2518\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 11s 138ms/step - loss: 13.3472\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.2949\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.6410\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.3999\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.4393\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.2546\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.9142\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 13.0815\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.3352\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.4429\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.0688\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.4846\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.3973\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.2123\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 11s 142ms/step - loss: 12.8275\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.9884\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.1670\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.1047\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.0361\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.1115\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.3135\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.1893\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.0085\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.3287\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 11s 146ms/step - loss: 12.9859\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.2351\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.2503\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.0607\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.1014\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.9148\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9175\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 12.9721\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.0160\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.8494\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.0769\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.0411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46f85fc790>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d1fbf7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 [==============================] - 12s 98ms/step - loss: 15.5466\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 14.0876\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.7544\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.3075\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.6482\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.4675\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 13.6814\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.6239\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.0276\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 12s 153ms/step - loss: 13.3434\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.4667\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.3233\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.4278\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.3000\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.3789\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.2924\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.6598\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.3597\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.4645\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.3006\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 10s 134ms/step - loss: 12.9523\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.0665\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.3334\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.4333\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.0611\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.5019\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.4934\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 13.2343\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 12.8177\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.9986\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.1478\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.0556\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.0732\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.1311\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.3395\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 13.1394\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.0046\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 10s 135ms/step - loss: 13.3607\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.0111\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.2548\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.2574\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.0958\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.0347\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9225\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.8290\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.0253\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9920\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.8467\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.0914\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.0302\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.1300\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9048\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 10s 131ms/step - loss: 12.8131\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.0348\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.1217\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.1212\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.0153\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.2008\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9011\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.0395\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9264\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.9217\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.8722\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 8s 108ms/step - loss: 13.0827\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.7474\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.0094\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 11s 146ms/step - loss: 13.0309\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.9750\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.9699\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.0543\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.6894\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 9s 111ms/step - loss: 12.9667\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 13.0114\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.5775\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.8111\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.9127\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.9581\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9111\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.7335\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.8286\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.8650\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.4084\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 11s 143ms/step - loss: 13.2306\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.8510\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.9351\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 12.7872\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.6761\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 13.0014\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 12.7152\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 12.8490\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 12.7734\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 13.1572\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 12.7508\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.8314\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.9321\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.0483\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 10s 137ms/step - loss: 12.8954\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.7541\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9781\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.9663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46e87e1280>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_fn = rmse_loss\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "381c99fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 12s 104ms/step - loss: 14.9223\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.9433\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.6449\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 13.2819\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.5724\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 8s 108ms/step - loss: 13.4860\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 13.6422\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 13.6212\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 13.0164\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 12s 154ms/step - loss: 13.3576\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 13.4080\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 13.3292\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 13.4249\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 13.2499\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 8s 108ms/step - loss: 13.3491\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 9s 111ms/step - loss: 13.2545\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 9s 111ms/step - loss: 13.5762\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 13.3561\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 13.3734\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.2667\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.9145\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.0343\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.3225\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 10s 131ms/step - loss: 13.4287\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 8s 110ms/step - loss: 13.0600\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.5021\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.4104\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.1838\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.7890\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.0093\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 13.1000\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 13.0664\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.0473\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.1404\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.3244\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.1684\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 12s 152ms/step - loss: 13.0345\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.2811\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.9693\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.2454\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 13.2534\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.0557\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.0347\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 8s 108ms/step - loss: 12.9568\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.8952\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.9642\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.9787\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.8503\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 11s 145ms/step - loss: 13.0465\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 13.0161\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 13.1494\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.8806\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.8173\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.0028\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.0598\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.0964\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.9862\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 13.1712\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 9s 111ms/step - loss: 12.8923\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 13.0499\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.8596\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.9480\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 12s 153ms/step - loss: 12.8671\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 13.1439\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.7799\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.9856\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.9920\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.9427\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 9s 111ms/step - loss: 12.9557\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.9694\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.6536\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 12.9242\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 12.9754\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 12.4857\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 12.8127\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 12s 152ms/step - loss: 12.9562\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.9317\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9188\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.6836\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.8104\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.8528\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 12.3757\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 13.1606\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.8419\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.9523\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 12.8085\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 12s 154ms/step - loss: 12.6919\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.9918\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.7100\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.8469\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.7719\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 13.1038\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 12.7142\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.8025\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9051\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 13.0463\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 8s 108ms/step - loss: 12.9131\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 12.7565\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.9586\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.9489\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.8380\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 12s 150ms/step - loss: 12.6387\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.8969\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.9228\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.9993\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.4767\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.7895\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.6365\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.7899\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 12.7146\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.7466\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.6833\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.7377\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 10s 136ms/step - loss: 12.9570\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.5542\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.6994\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.7958\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.9316\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.8262\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 12.5917\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.5325\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.7287\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.6696\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 13.0685\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.7701\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 12.7005\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 12.7536\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.5469\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 11s 141ms/step - loss: 12.7077\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.5834\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 8s 108ms/step - loss: 12.6344\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.8221\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 8s 108ms/step - loss: 12.6359\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 13.0331\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 8s 108ms/step - loss: 12.7008\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 12.6218\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.6347\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.6986\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.8727\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 12.4438\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.6123\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 15s 195ms/step - loss: 12.6671\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 12.6526\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 12.8791\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 8s 108ms/step - loss: 12.6973\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 12.5389\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 12.4764\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 12.7355\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 12.6097\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 12.5175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46cc384220>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 150\n",
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_fn = rmse_loss\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "055fb4af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "77/77 [==============================] - 12s 96ms/step - loss: 15.4870\n",
      "Epoch 2/200\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 14.0569\n",
      "Epoch 3/200\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.7952\n",
      "Epoch 4/200\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 13.4087\n",
      "Epoch 5/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.6161\n",
      "Epoch 6/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.4954\n",
      "Epoch 7/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.7052\n",
      "Epoch 8/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.6811\n",
      "Epoch 9/200\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 13.0129\n",
      "Epoch 10/200\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 13.3911\n",
      "Epoch 11/200\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 13.3794\n",
      "Epoch 12/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.3289\n",
      "Epoch 13/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.4802\n",
      "Epoch 14/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.2848\n",
      "Epoch 15/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.3875\n",
      "Epoch 16/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.3004\n",
      "Epoch 17/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.7036\n",
      "Epoch 18/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.4042\n",
      "Epoch 19/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.4962\n",
      "Epoch 20/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.3079\n",
      "Epoch 21/200\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.9459\n",
      "Epoch 22/200\n",
      "77/77 [==============================] - 10s 128ms/step - loss: 13.1211\n",
      "Epoch 23/200\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 13.4162\n",
      "Epoch 24/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.4433\n",
      "Epoch 25/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.1422\n",
      "Epoch 26/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.5124\n",
      "Epoch 27/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.4356\n",
      "Epoch 28/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.1945\n",
      "Epoch 29/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.7928\n",
      "Epoch 30/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.9999\n",
      "Epoch 31/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.1575\n",
      "Epoch 32/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 13.0602\n",
      "Epoch 33/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.0943\n",
      "Epoch 34/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.1497\n",
      "Epoch 35/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 13.3609\n",
      "Epoch 36/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.2005\n",
      "Epoch 37/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 13.0758\n",
      "Epoch 38/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.4120\n",
      "Epoch 39/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9601\n",
      "Epoch 40/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.2457\n",
      "Epoch 41/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.2970\n",
      "Epoch 42/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0692\n",
      "Epoch 43/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.1343\n",
      "Epoch 44/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.9416\n",
      "Epoch 45/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8771\n",
      "Epoch 46/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.0310\n",
      "Epoch 47/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9918\n",
      "Epoch 48/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.7866\n",
      "Epoch 49/200\n",
      "77/77 [==============================] - 9s 119ms/step - loss: 13.1403\n",
      "Epoch 50/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0287\n",
      "Epoch 51/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.1586\n",
      "Epoch 52/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9427\n",
      "Epoch 53/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8172\n",
      "Epoch 54/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.0049\n",
      "Epoch 55/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.0670\n",
      "Epoch 56/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.1201\n",
      "Epoch 57/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0412\n",
      "Epoch 58/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.2535\n",
      "Epoch 59/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8725\n",
      "Epoch 60/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.0727\n",
      "Epoch 61/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9196\n",
      "Epoch 62/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9559\n",
      "Epoch 63/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8804\n",
      "Epoch 64/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.1668\n",
      "Epoch 65/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.7547\n",
      "Epoch 66/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9784\n",
      "Epoch 67/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9873\n",
      "Epoch 68/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.9601\n",
      "Epoch 69/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9760\n",
      "Epoch 70/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0594\n",
      "Epoch 71/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.6572\n",
      "Epoch 72/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9517\n",
      "Epoch 73/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0102\n",
      "Epoch 74/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.5131\n",
      "Epoch 75/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8390\n",
      "Epoch 76/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9651\n",
      "Epoch 77/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9781\n",
      "Epoch 78/200\n",
      "77/77 [==============================] - 9s 117ms/step - loss: 12.9379\n",
      "Epoch 79/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.6849\n",
      "Epoch 80/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8414\n",
      "Epoch 81/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8588\n",
      "Epoch 82/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.4306\n",
      "Epoch 83/200\n",
      "77/77 [==============================] - 7s 90ms/step - loss: 13.2156\n",
      "Epoch 84/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.8267\n",
      "Epoch 85/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9625\n",
      "Epoch 86/200\n",
      "77/77 [==============================] - 7s 90ms/step - loss: 12.8378\n",
      "Epoch 87/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.6850\n",
      "Epoch 88/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 13.0047\n",
      "Epoch 89/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.7194\n",
      "Epoch 90/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8682\n",
      "Epoch 91/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.7840\n",
      "Epoch 92/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.1368\n",
      "Epoch 93/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.7358\n",
      "Epoch 94/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8426\n",
      "Epoch 95/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.9060\n",
      "Epoch 96/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 13.0470\n",
      "Epoch 97/200\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 12.8951\n",
      "Epoch 98/200\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 12.7654\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 7s 92ms/step - loss: 12.9758\n",
      "Epoch 100/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.9770\n",
      "Epoch 101/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8791\n",
      "Epoch 102/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.6094\n",
      "Epoch 103/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.9395\n",
      "Epoch 104/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8842\n",
      "Epoch 105/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 13.0374\n",
      "Epoch 106/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.4947\n",
      "Epoch 107/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.7363\n",
      "Epoch 108/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6492\n",
      "Epoch 109/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8198\n",
      "Epoch 110/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7683\n",
      "Epoch 111/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.7720\n",
      "Epoch 112/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.6930\n",
      "Epoch 113/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.7725\n",
      "Epoch 114/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.9692\n",
      "Epoch 115/200\n",
      "77/77 [==============================] - 9s 116ms/step - loss: 12.5883\n",
      "Epoch 116/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.7622\n",
      "Epoch 117/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8186\n",
      "Epoch 118/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.9060\n",
      "Epoch 119/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8580\n",
      "Epoch 120/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.6160\n",
      "Epoch 121/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.5405\n",
      "Epoch 122/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.7475\n",
      "Epoch 123/200\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.6802\n",
      "Epoch 124/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 13.0577\n",
      "Epoch 125/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.7921\n",
      "Epoch 126/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.6996\n",
      "Epoch 127/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7660\n",
      "Epoch 128/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.5614\n",
      "Epoch 129/200\n",
      "77/77 [==============================] - 9s 123ms/step - loss: 12.7214\n",
      "Epoch 130/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.5599\n",
      "Epoch 131/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6634\n",
      "Epoch 132/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8627\n",
      "Epoch 133/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.6401\n",
      "Epoch 134/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 13.0234\n",
      "Epoch 135/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7089\n",
      "Epoch 136/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6448\n",
      "Epoch 137/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6294\n",
      "Epoch 138/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6773\n",
      "Epoch 139/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.8831\n",
      "Epoch 140/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.4486\n",
      "Epoch 141/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.6121\n",
      "Epoch 142/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6759\n",
      "Epoch 143/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.6474\n",
      "Epoch 144/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8610\n",
      "Epoch 145/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.7192\n",
      "Epoch 146/200\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 12.5586\n",
      "Epoch 147/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.4675\n",
      "Epoch 148/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7521\n",
      "Epoch 149/200\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.6352\n",
      "Epoch 150/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.5351\n",
      "Epoch 151/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.8531\n",
      "Epoch 152/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.7473\n",
      "Epoch 153/200\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 12.4323\n",
      "Epoch 154/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7714\n",
      "Epoch 155/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7090\n",
      "Epoch 156/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.4789\n",
      "Epoch 157/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.3916\n",
      "Epoch 158/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7708\n",
      "Epoch 159/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7267\n",
      "Epoch 160/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8058\n",
      "Epoch 161/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7527\n",
      "Epoch 162/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.5904\n",
      "Epoch 163/200\n",
      "77/77 [==============================] - 10s 127ms/step - loss: 12.6747\n",
      "Epoch 164/200\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 12.7604\n",
      "Epoch 165/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.4962\n",
      "Epoch 166/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.6584\n",
      "Epoch 167/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6896\n",
      "Epoch 168/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.8841\n",
      "Epoch 169/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.5054\n",
      "Epoch 170/200\n",
      "77/77 [==============================] - 7s 95ms/step - loss: 12.5989\n",
      "Epoch 171/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.4027\n",
      "Epoch 172/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7673\n",
      "Epoch 173/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.3631\n",
      "Epoch 174/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.7012\n",
      "Epoch 175/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.6382\n",
      "Epoch 176/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.5501\n",
      "Epoch 177/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.7535\n",
      "Epoch 178/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.5853\n",
      "Epoch 179/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8043\n",
      "Epoch 180/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7148\n",
      "Epoch 181/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.4380\n",
      "Epoch 182/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.7133\n",
      "Epoch 183/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.7989\n",
      "Epoch 184/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.8678\n",
      "Epoch 185/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6370\n",
      "Epoch 186/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.5390\n",
      "Epoch 187/200\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 12.6816\n",
      "Epoch 188/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.6826\n",
      "Epoch 189/200\n",
      "77/77 [==============================] - 7s 94ms/step - loss: 12.3242\n",
      "Epoch 190/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.4614\n",
      "Epoch 191/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.6179\n",
      "Epoch 192/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.8486\n",
      "Epoch 193/200\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 12.3652\n",
      "Epoch 194/200\n",
      "77/77 [==============================] - 7s 97ms/step - loss: 12.3647\n",
      "Epoch 195/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.5636\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 7s 92ms/step - loss: 12.5300\n",
      "Epoch 197/200\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 12.2884\n",
      "Epoch 198/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.6437\n",
      "Epoch 199/200\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 12.5554\n",
      "Epoch 200/200\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 12.6519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46f86c9640>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 200\n",
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_fn = rmse_loss\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "654a8166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 2s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Getting prediction result from test set\n",
    "'''\n",
    "y_pred = full_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9c402ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./PCLR_finetuned_100epc.pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./PCLR_finetuned_100epc.pb/assets\n"
     ]
    }
   ],
   "source": [
    "full_model.save('./PCLR_finetuned_100epc.pb', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da385cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved tf model\n",
    "loaded_model = tf.keras.models.load_model('./PCLR_finetuned.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab0b27b",
   "metadata": {},
   "source": [
    "# Calculate Classification Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d07769dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(11.718298284532933, shape=(), dtype=float64)\n",
      "0.5179734023757416 1.7000212654359237e-64\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "r, pval = stats.pearsonr(y_test, np.concatenate(y_pred))\n",
    "print(rmse_loss(y_test, y_pred))\n",
    "print(r, pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "623d3acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.662241673856977 0.5168803322877793 3.885793744767385e-48\n",
      "(10.168321327256356, 11.186809058909072) (0.46935757473184414, 0.5653645253170076) (4.403350490234938e-79, 9.551261205355765e-52)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "50 epoch model\n",
    "'''\n",
    "rmse, r, pval = do_bootstrap_regression(np.concatenate(y_pred), y_test)\n",
    "print(rmse.mean(), r.mean(), pval.mean())\n",
    "print(confidence_interval(rmse), confidence_interval(r), confidence_interval(pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ecb6653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.08667670973824 0.5084383288648698 5.124600599466284e-44\n",
      "(9.593113688193553, 10.608999002632787) (0.4534978599475333, 0.5592618550246696) (4.559193565980286e-77, 5.1785051956098e-48)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "100 epoch model\n",
    "'''\n",
    "rmse, r, pval = do_bootstrap_regression(np.concatenate(y_pred), y_test)\n",
    "print(rmse.mean(), r.mean(), pval.mean())\n",
    "print(confidence_interval(rmse), confidence_interval(r), confidence_interval(pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4ea977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.848489722993618 0.46944465590783035 3.0449579264607663e-35\n",
      "(9.338509122190928, 10.366695124278358) (0.4179658931128352, 0.5250832141152932) (1.53915223843851e-66, 2.4962666858646983e-40)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "150 epoch model\n",
    "'''\n",
    "rmse, r, pval = do_bootstrap_regression(np.concatenate(y_pred), y_test)\n",
    "print(rmse.mean(), r.mean(), pval.mean())\n",
    "print(confidence_interval(rmse), confidence_interval(r), confidence_interval(pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01ccda36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.292663228474936 0.47730382296197216 2.970788508126865e-37\n",
      "(9.783613390282376, 10.830710205153133) (0.42562339353459316, 0.5319061016216475) (1.5150117569838069e-68, 6.574814400434942e-42)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "200 epoch model\n",
    "'''\n",
    "rmse, r, pval = do_bootstrap_regression(np.concatenate(y_pred), y_test)\n",
    "print(rmse.mean(), r.mean(), pval.mean())\n",
    "print(confidence_interval(rmse), confidence_interval(r), confidence_interval(pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8681c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
