{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c1c0097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 13:29:55.883613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Hyewon Jeong\n",
    "Last Modified: January 20, 2âˆ‚22\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, average_precision_score, f1_score, accuracy_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from scipy import stats\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from src.hnet import AppendNet\n",
    "from src.utils import do_bootstrap, confidence_interval\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "def load_pretrained_model(pre_trained_loc=\"./PCLR.h5\") :\n",
    "    pre_trained_model = load_model(pre_trained_loc)\n",
    "    \n",
    "    return pre_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "249d61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ecg(df):\n",
    "    ecgs = []\n",
    "    for idx in df.index:\n",
    "        row = df.loc[idx]\n",
    "        qid = row['QuantaID']\n",
    "        doc = row['Date_of_Cath']\n",
    "        fname = f'/storage/shared/apollo/same-day/{qid}_{doc}.csv'\n",
    "        x = pd.read_csv(fname).values[...,1:].astype(np.float32)\n",
    "        x /= 1000\n",
    "        x = x[:4096, :].T\n",
    "        ecgs.append(x)\n",
    "        \n",
    "    ecgs = np.array(ecgs)\n",
    "    return np.transpose(ecgs, (0,2,1))\n",
    "\n",
    "def get_data(batch_size=64, agegap = False):\n",
    "    df_tab = pd.read_csv(os.path.join('/storage/shared/apollo/same-day/tabular_data.csv'))\n",
    "    train_ids = np.load(\"./stores/train_ids.npy\")\n",
    "    val_ids = np.load(\"./stores/val_ids.npy\")\n",
    "    test_ids = np.load(\"./stores/test_ids.npy\")\n",
    "    \n",
    "    train_ids = train_ids[len(train_ids) // 2 :]\n",
    "    val_ids = val_ids[len(val_ids) // 2 :]\n",
    "    test_ids = test_ids[len(test_ids) // 2 :]\n",
    "\n",
    "    train_df = df_tab[df_tab[\"QuantaID\"].isin(train_ids)]\n",
    "    val_df = df_tab[df_tab[\"QuantaID\"].isin(val_ids)]\n",
    "    test_df = df_tab[df_tab[\"QuantaID\"].isin(test_ids)]\n",
    "    print(len(train_df), len(val_df), len(test_df))\n",
    "        \n",
    "    X_train = get_ecg(train_df)\n",
    "    X_val = get_ecg(val_df)\n",
    "    X_test = get_ecg(test_df)\n",
    "\n",
    "    y_train = (train_df[\"PCWP_mean\"].values >= 18).astype('float32')\n",
    "    y_val = (val_df[\"PCWP_mean\"].values >= 18).astype('float32')\n",
    "    y_test = (test_df[\"PCWP_mean\"].values >= 18).astype('float32')\n",
    "\n",
    "    if agegap==True:\n",
    "        age_groups = {\n",
    "            1: (18, 35),\n",
    "            2: (35, 50),\n",
    "            3: (50, 75),\n",
    "            4: (75, 100)\n",
    "        }\n",
    "\n",
    "        # Function to map age to age group\n",
    "        def map_age_to_group(age):\n",
    "            for group, (min_age, max_age) in age_groups.items():\n",
    "                if min_age <= age < max_age:\n",
    "                    return group\n",
    "            return None\n",
    "\n",
    "        # Create a new column in the dataframe to indicate the age group for each row\n",
    "        test_df['Age_Group'] = test_df['Age_at_Cath'].apply(map_age_to_group)\n",
    "        \n",
    "        age1_df = test_df[test_df['Age_Group'] == 1]\n",
    "        age2_df = test_df[test_df['Age_Group'] == 2]\n",
    "        age3_df = test_df[test_df['Age_Group'] == 3]\n",
    "        age4_df = test_df[test_df['Age_Group'] == 4]\n",
    "\n",
    "        age1_test = get_ecg(age1_df)\n",
    "        age2_test = get_ecg(age2_df)\n",
    "        age3_test = get_ecg(age3_df)\n",
    "        age4_test = get_ecg(age4_df)\n",
    "\n",
    "        y_age1 = (age1_df[\"PCWP_mean\"].values >= 18).astype('float32')\n",
    "        y_age2 = (age2_df[\"PCWP_mean\"].values >= 18).astype('float32')\n",
    "        y_age3 = (age3_df[\"PCWP_mean\"].values >= 18).astype('float32')\n",
    "        y_age4 = (age4_df[\"PCWP_mean\"].values >= 18).astype('float32')\n",
    "\n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test, age1_test, y_age1, age2_test, y_age2, age3_test, y_age3, age4_test, y_age4\n",
    "\n",
    "    else:\n",
    "        male_ids = np.load(\"./stores/test_female_ids.npy\")\n",
    "        female_ids = np.load(\"./stores/test_male_ids.npy\")\n",
    "\n",
    "        male_df = df_tab[df_tab[\"QuantaID\"].isin(male_ids)]\n",
    "        female_df = df_tab[df_tab[\"QuantaID\"].isin(female_ids)]\n",
    "        print(len(male_df), len(female_df))\n",
    "\n",
    "        male_test = get_ecg(male_df)\n",
    "        female_test = get_ecg(female_df)\n",
    "\n",
    "        y_male = (male_df[\"PCWP_mean\"].values >= 18).astype('float32')\n",
    "        y_female = (female_df[\"PCWP_mean\"].values >= 18).astype('float32')\n",
    "\n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test, male_test, y_male, female_test, y_female\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25647daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 02:21:24.292944: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-26 02:21:25.753731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 28766 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3e:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "2442 893 923\n",
      "1114 711\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, male_test, y_male, female_test, y_female = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df34dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 02:22:23.653837: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-07-26 02:22:24.478271: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-26 02:22:24.480165: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-26 02:22:24.480207: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-07-26 02:22:24.482338: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-26 02:22:24.482469: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 11s 62ms/step - loss: 1.8153\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 0.8507\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 0.6789\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 6s 82ms/step - loss: 0.6187\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.6071\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.6220\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 6s 83ms/step - loss: 0.6186\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 6s 75ms/step - loss: 0.6091\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 6s 75ms/step - loss: 0.5883\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 5s 66ms/step - loss: 0.5816\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 0.5821\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 0.5873\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 0.5865\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 6s 72ms/step - loss: 0.5855\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 6s 77ms/step - loss: 0.5759\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 6s 81ms/step - loss: 0.5862\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 0.5769\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 6s 77ms/step - loss: 0.5706\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 6s 79ms/step - loss: 0.5827\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.5785\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 0.5789\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 0.5733\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 0.5565\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 0.5582\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.5564\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 6s 72ms/step - loss: 0.5636\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.5607\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.5701\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 6s 83ms/step - loss: 0.5562\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.5588\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 0.5511\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 6s 75ms/step - loss: 0.5384\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 5s 62ms/step - loss: 0.5616\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 0.5541\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 0.5492\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 0.5474\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 6s 80ms/step - loss: 0.5504\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 6s 79ms/step - loss: 0.5469\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.5380\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.5373\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 6s 75ms/step - loss: 0.5495\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 6s 77ms/step - loss: 0.5423\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.5438\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.5254\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 0.5150\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 0.5207\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 0.5309\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 6s 75ms/step - loss: 0.5292\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 6s 80ms/step - loss: 0.5179\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 0.5051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd2300aae20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "742b839a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/40\n",
      "77/77 [==============================] - 9s 56ms/step - loss: 5.6152\n",
      "Epoch 2/40\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.5585\n",
      "Epoch 3/40\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.5585\n",
      "Epoch 4/40\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.5585\n",
      "Epoch 5/40\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.5585\n",
      "Epoch 6/40\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.5585\n",
      "Epoch 7/40\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.5585\n",
      "Epoch 8/40\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 5.5585\n",
      "Epoch 9/40\n",
      "77/77 [==============================] - 5s 63ms/step - loss: 5.5585\n",
      "Epoch 10/40\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.5585\n",
      "Epoch 11/40\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.5585\n",
      "Epoch 12/40\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.5585\n",
      "Epoch 13/40\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.5585\n",
      "Epoch 14/40\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.5585\n",
      "Epoch 15/40\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.5585\n",
      "Epoch 16/40\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.5585\n",
      "Epoch 17/40\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.5585\n",
      "Epoch 18/40\n",
      "77/77 [==============================] - 5s 58ms/step - loss: 5.5585\n",
      "Epoch 19/40\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.5585\n",
      "Epoch 20/40\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.5585\n",
      "Epoch 21/40\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.5585\n",
      "Epoch 22/40\n",
      "77/77 [==============================] - 5s 61ms/step - loss: 5.5585\n",
      "Epoch 23/40\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 5.5585\n",
      "Epoch 24/40\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.5585\n",
      "Epoch 25/40\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 5.5585\n",
      "Epoch 26/40\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.5585\n",
      "Epoch 27/40\n",
      "77/77 [==============================] - 5s 61ms/step - loss: 5.5585\n",
      "Epoch 28/40\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.5585\n",
      "Epoch 29/40\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.5585\n",
      "Epoch 30/40\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.5585\n",
      "Epoch 31/40\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.5585\n",
      "Epoch 32/40\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.5585\n",
      "Epoch 33/40\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.5585\n",
      "Epoch 34/40\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.5585\n",
      "Epoch 35/40\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.5585\n",
      "Epoch 36/40\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.5585\n",
      "Epoch 37/40\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.5585\n",
      "Epoch 38/40\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.5585\n",
      "Epoch 39/40\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 5.5585\n",
      "Epoch 40/40\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 5.5585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f17f466b790>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 40\n",
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b86ef362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/60\n",
      "77/77 [==============================] - 8s 52ms/step - loss: 5.7474\n",
      "Epoch 2/60\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 5.3227\n",
      "Epoch 3/60\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 5.1879\n",
      "Epoch 4/60\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.2043\n",
      "Epoch 5/60\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 5.2899\n",
      "Epoch 6/60\n",
      "77/77 [==============================] - 5s 62ms/step - loss: 5.0397\n",
      "Epoch 7/60\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 5.0758\n",
      "Epoch 8/60\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.0316\n",
      "Epoch 9/60\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 4.9309\n",
      "Epoch 10/60\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.0144\n",
      "Epoch 11/60\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 4.8389\n",
      "Epoch 12/60\n",
      "77/77 [==============================] - 5s 61ms/step - loss: 4.9376\n",
      "Epoch 13/60\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.4239\n",
      "Epoch 14/60\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.0567\n",
      "Epoch 15/60\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 5.0014\n",
      "Epoch 16/60\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.0824\n",
      "Epoch 17/60\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.2095\n",
      "Epoch 18/60\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 5.1781\n",
      "Epoch 19/60\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 5.1131\n",
      "Epoch 20/60\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.1375\n",
      "Epoch 21/60\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.0255\n",
      "Epoch 22/60\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 5.0818\n",
      "Epoch 23/60\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.1082\n",
      "Epoch 24/60\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.1913\n",
      "Epoch 25/60\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.1726\n",
      "Epoch 26/60\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.3303\n",
      "Epoch 27/60\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.2612\n",
      "Epoch 28/60\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.2428\n",
      "Epoch 29/60\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.1473\n",
      "Epoch 30/60\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.1345\n",
      "Epoch 31/60\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 4.9178\n",
      "Epoch 32/60\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.0963\n",
      "Epoch 33/60\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.2032\n",
      "Epoch 34/60\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.1933\n",
      "Epoch 35/60\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 5.2930\n",
      "Epoch 36/60\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.1792\n",
      "Epoch 37/60\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.0315\n",
      "Epoch 38/60\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 5.0672\n",
      "Epoch 39/60\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.5063\n",
      "Epoch 40/60\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 7.5411\n",
      "Epoch 41/60\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.5882\n",
      "Epoch 42/60\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.3178\n",
      "Epoch 43/60\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.5368\n",
      "Epoch 44/60\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 7.6304\n",
      "Epoch 45/60\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.6866\n",
      "Epoch 46/60\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 7.5694\n",
      "Epoch 47/60\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 6.2989\n",
      "Epoch 48/60\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.9744\n",
      "Epoch 49/60\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.7424\n",
      "Epoch 50/60\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.7645\n",
      "Epoch 51/60\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.8793\n",
      "Epoch 52/60\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 4.9954\n",
      "Epoch 53/60\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 4.9659\n",
      "Epoch 54/60\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.0604\n",
      "Epoch 55/60\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 4.9008\n",
      "Epoch 56/60\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.2822\n",
      "Epoch 57/60\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.1521\n",
      "Epoch 58/60\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.4792\n",
      "Epoch 59/60\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.2608\n",
      "Epoch 60/60\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.2395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f181447fb50>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 60\n",
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ebfd175e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/75\n",
      "77/77 [==============================] - 9s 54ms/step - loss: 5.5017\n",
      "Epoch 2/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 6.7143\n",
      "Epoch 3/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.8228\n",
      "Epoch 4/75\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.1356\n",
      "Epoch 5/75\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 5.2710\n",
      "Epoch 6/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.2711\n",
      "Epoch 7/75\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.1118\n",
      "Epoch 8/75\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.1244\n",
      "Epoch 9/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.1332\n",
      "Epoch 10/75\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 4.9833\n",
      "Epoch 11/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.0741\n",
      "Epoch 12/75\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 5.0246\n",
      "Epoch 13/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 7.2800\n",
      "Epoch 14/75\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 6.2620\n",
      "Epoch 15/75\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 4.8606\n",
      "Epoch 16/75\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 5.0230\n",
      "Epoch 17/75\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.1313\n",
      "Epoch 18/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 4.8755\n",
      "Epoch 19/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 4.8433\n",
      "Epoch 20/75\n",
      "77/77 [==============================] - 5s 62ms/step - loss: 5.0550\n",
      "Epoch 21/75\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 4.8885\n",
      "Epoch 22/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.3580\n",
      "Epoch 23/75\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.9854\n",
      "Epoch 24/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.1391\n",
      "Epoch 25/75\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 4.7901\n",
      "Epoch 26/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.0211\n",
      "Epoch 27/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 4.8629\n",
      "Epoch 28/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 4.9313\n",
      "Epoch 29/75\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 4.6494\n",
      "Epoch 30/75\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 4.7896\n",
      "Epoch 31/75\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 4.7179\n",
      "Epoch 32/75\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 4.8375\n",
      "Epoch 33/75\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 4.8006\n",
      "Epoch 34/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.1261\n",
      "Epoch 35/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.2731\n",
      "Epoch 36/75\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 5.2414\n",
      "Epoch 37/75\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.2605\n",
      "Epoch 38/75\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.3177\n",
      "Epoch 39/75\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.2205\n",
      "Epoch 40/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.0641\n",
      "Epoch 41/75\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 5.1886\n",
      "Epoch 42/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.1385\n",
      "Epoch 43/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.2088\n",
      "Epoch 44/75\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 4.9209\n",
      "Epoch 45/75\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 4.7422\n",
      "Epoch 46/75\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 4.8860\n",
      "Epoch 47/75\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 4.7036\n",
      "Epoch 48/75\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 4.7722\n",
      "Epoch 49/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.1267\n",
      "Epoch 50/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.1124\n",
      "Epoch 51/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 4.9656\n",
      "Epoch 52/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 4.9468\n",
      "Epoch 53/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 4.8217\n",
      "Epoch 54/75\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 4.8951\n",
      "Epoch 55/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 4.9085\n",
      "Epoch 56/75\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 4.9892\n",
      "Epoch 57/75\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 4.8500\n",
      "Epoch 58/75\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 4.9137\n",
      "Epoch 59/75\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 4.9804\n",
      "Epoch 60/75\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 5.2798\n",
      "Epoch 61/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.3588\n",
      "Epoch 62/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.2168\n",
      "Epoch 63/75\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 5.2022\n",
      "Epoch 64/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.2408\n",
      "Epoch 65/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.1387\n",
      "Epoch 66/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.1851\n",
      "Epoch 67/75\n",
      "77/77 [==============================] - 5s 61ms/step - loss: 5.1259\n",
      "Epoch 68/75\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.1258\n",
      "Epoch 69/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.0755\n",
      "Epoch 70/75\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.0635\n",
      "Epoch 71/75\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.0825\n",
      "Epoch 72/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.1090\n",
      "Epoch 73/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.1952\n",
      "Epoch 74/75\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 4.8870\n",
      "Epoch 75/75\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 4.7292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f18244f7940>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 75\n",
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "514c438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 9s 54ms/step - loss: 5.9893\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.5585\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.5596\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 5.5209\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 7.3218\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.7875\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 7.4752\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 7.8457\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 7.4221\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 7.7688\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 7.5437\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.5054\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 7.8384\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 7.6247\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.5438\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.4994\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 8.0153\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 7.7440\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.6387\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 7.7624\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.3471\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.4864\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 7.8824\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 8.0077\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.4480\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 7.7456\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 7.6823\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 7.4439\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 7.3911\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 7.2611\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.7565\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.7682\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 7.3807\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 7.5875\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 7.7889\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 7.7880\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 5s 62ms/step - loss: 7.5435\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.6951\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.9686\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.8454\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 7.5882\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.3115\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.5556\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 7.6491\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 7.7116\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.6746\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 7.5745\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.5546\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 7.8447\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.6184\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 6.8627\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 6.1009\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.4122\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.7119\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 7.5060\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.8512\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.5938\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 7.7330\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 7.5002\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.8179\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.3554\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.1586\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.0680\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 4.9295\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 4.8671\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 5.1027\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.0635\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 4.9567\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 4.9793\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 4.9731\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.0937\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.1034\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.0793\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 5.2676\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.0306\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.0851\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.0644\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 5.1246\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 4.9933\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 4.9031\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 4.9336\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 4.8008\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.0165\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 4.9229\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 4.9402\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 4.7883\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 4.7548\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 4.9120\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 4.7648\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.0382\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 4.9945\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.0124\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 5.0189\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 4.9100\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.0022\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 5.0594\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 5.0718\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 5.0149\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 4.9271\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 4.8636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f18243f9850>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "pre_trained_model = load_pretrained_model(pre_trained_loc='./PCLR.h5')\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "full_model = AppendNet(latent, new_layers = [128, 1], classification=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e05d0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = full_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9c402ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./PCLR_finetuned_50epc.pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./PCLR_finetuned_50epc.pb/assets\n"
     ]
    }
   ],
   "source": [
    "full_model.save('./PCLR_finetuned_50epc.pb', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da385cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved tf model\n",
    "loaded_model = tf.keras.models.load_model('./PCLR_finetuned.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab0b27b",
   "metadata": {},
   "source": [
    "# Calculate Classification Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3798cfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.3351798483206934 0.6648201516793067 0.0\n",
      "(0.5, 0.5) (0.3054983748645721, 0.36619718309859156) (0.6338028169014085, 0.6945016251354279) (0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "40 epoch performance\n",
    "'''\n",
    "auc, apr, acc, f1 = do_bootstrap(y_pred, y_test)\n",
    "print(np.mean(auc), np.mean(apr), np.mean(acc), np.mean(f1))\n",
    "print(confidence_interval(auc), confidence_interval(apr), confidence_interval(acc), confidence_interval(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d460af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7420528515663946 0.5421483349852821 0.764765980498375 0.657019720442488\n",
      "(0.710537134846387, 0.7732459181343004) (0.4917146161878393, 0.5885634218398414) (0.7356446370530878, 0.7930660888407367) (0.612448111043782, 0.697387040714995)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "50 epoch performance\n",
    "'''\n",
    "auc, apr, acc, f1 = do_bootstrap(y_pred, y_test)\n",
    "print(np.mean(auc), np.mean(apr), np.mean(acc), np.mean(f1))\n",
    "print(confidence_interval(auc), confidence_interval(apr), confidence_interval(acc), confidence_interval(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee409f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7135456404202721 0.5147116587344185 0.7492231852654389 0.6176315236672565\n",
      "(0.6807510494291622, 0.7442520302960727) (0.46605857220647273, 0.5586640078494626) (0.7204767063921993, 0.7757313109425785) (0.5704333546209287, 0.6613424879493288)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60 epoch performance\n",
    "'''\n",
    "auc, apr, acc, f1 = do_bootstrap(y_pred, y_test)\n",
    "print(np.mean(auc), np.mean(apr), np.mean(acc), np.mean(f1))\n",
    "print(confidence_interval(auc), confidence_interval(apr), confidence_interval(acc), confidence_interval(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b9fa05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6846302660676242 0.49376882366816766 0.7417410617551463 0.5698951463946115\n",
      "(0.6541804733822344, 0.7145397546030037) (0.446385566822725, 0.5395325749227305) (0.71397616468039, 0.7681473456121344) (0.5187803713988198, 0.6164033145865742)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "75 epoch performance\n",
    "'''\n",
    "auc, apr, acc, f1 = do_bootstrap(y_pred, y_test)\n",
    "print(np.mean(auc), np.mean(apr), np.mean(acc), np.mean(f1))\n",
    "print(confidence_interval(auc), confidence_interval(apr), confidence_interval(acc), confidence_interval(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7941a83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6990473923899231 0.5073281407432844 0.7491733477789816 0.5933705207643143\n",
      "(0.6673062791552481, 0.7294901458721476) (0.45789507885597597, 0.5547084949493752) (0.7215330444203684, 0.7757313109425785) (0.5428037459117965, 0.6393197278911565)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "100 epoch performance\n",
    "'''\n",
    "auc, apr, acc, f1 = do_bootstrap(y_pred, y_test)\n",
    "print(np.mean(auc), np.mean(apr), np.mean(acc), np.mean(f1))\n",
    "print(confidence_interval(auc), confidence_interval(apr), confidence_interval(acc), confidence_interval(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac16122a",
   "metadata": {},
   "source": [
    "# Subgroup Performance: Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecc3e18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 14ms/step\n",
      "0.7420528515663946 0.5421483349852821 0.764765980498375 0.657019720442488\n",
      "(0.710537134846387, 0.7732459181343004) (0.4917146161878393, 0.5885634218398414) (0.7356446370530878, 0.7930660888407367) (0.612448111043782, 0.697387040714995)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "50 epoch performance\n",
    "'''\n",
    "y_pred = full_model.predict(X_test)\n",
    "auc, apr, acc, f1 = do_bootstrap(y_pred, y_test)\n",
    "print(np.mean(auc), np.mean(apr), np.mean(acc), np.mean(f1))\n",
    "print(confidence_interval(auc), confidence_interval(apr), confidence_interval(acc), confidence_interval(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ace5b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 18ms/step\n",
      "0.7507258753965594 0.5393680476546086 0.7739066427289049 0.6610411363480164\n",
      "(0.7209960206231019, 0.7786899808832602) (0.4929084617692631, 0.5817191733975555) (0.7477558348294434, 0.7998204667863554) (0.6192317920714843, 0.6986132944082641)\n"
     ]
    }
   ],
   "source": [
    "male_pred = full_model.predict(male_test)\n",
    "auc_male, apr_male, acc_male, f1_male = do_bootstrap(male_pred, y_male)\n",
    "print(np.mean(auc_male), np.mean(apr_male), np.mean(acc_male), np.mean(f1_male))\n",
    "print(confidence_interval(auc_male), confidence_interval(apr_male), confidence_interval(acc_male), confidence_interval(f1_male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9701b18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 14ms/step\n",
      "0.7189093939892324 0.5802674796823021 0.7468917018284107 0.6454017769165924\n",
      "(0.6865776801415433, 0.7523731434920649) (0.5262370606713961, 0.6316654388471022) (0.7144866385372715, 0.7777777777777778) (0.5963359956051386, 0.6918526838966204)\n"
     ]
    }
   ],
   "source": [
    "female_pred = full_model.predict(female_test)\n",
    "auc_female, apr_female, acc_female, f1_female = do_bootstrap(female_pred, y_female)\n",
    "print(np.mean(auc_female), np.mean(apr_female), np.mean(acc_female), np.mean(f1_female))\n",
    "print(confidence_interval(auc_female), confidence_interval(apr_female), confidence_interval(acc_female), confidence_interval(f1_female))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1688e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/auc.npy', auc)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/apr.npy', apr)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/acc.npy', acc)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/f1.npy', f1)\n",
    "\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/auc_male.npy', auc_male)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/apr_male.npy', apr_male)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/acc_male.npy', acc_male)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/f1_male.npy', f1_male)\n",
    "\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/auc_female.npy', auc_female)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/apr_female.npy', apr_female)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/acc_female.npy', acc_female)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/f1_female.npy', f1_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d38da943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis test:\n",
      "  Statistic: 1043.7631107089233\n",
      "  p-value: 5.520066360748927e-229\n",
      "\n",
      "Independent t-test:\n",
      "  Statistic: 44.360812155488276\n",
      "  p-value: 9.057658498841297e-300\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Kruskal-Wallis test\n",
    "kruskal_stat, kruskal_p_value = stats.kruskal(auc_male, auc_female)\n",
    "print(\"Kruskal-Wallis test:\")\n",
    "print(\"  Statistic:\", kruskal_stat)\n",
    "print(\"  p-value:\", kruskal_p_value)\n",
    "\n",
    "# Independent t-test\n",
    "t_stat, t_p_value = stats.ttest_ind(auc_male, auc_female)\n",
    "print(\"\\nIndependent t-test:\")\n",
    "print(\"  Statistic:\", t_stat)\n",
    "print(\"  p-value:\", t_p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b165c631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis test:\n",
      "  Statistic: 837.0163653948283\n",
      "  p-value: 4.833496299067937e-184\n",
      "\n",
      "Independent t-test:\n",
      "  Statistic: -36.16394216400008\n",
      "  p-value: 9.686798304732356e-221\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Kruskal-Wallis test\n",
    "kruskal_stat, kruskal_p_value = stats.kruskal(apr_male, apr_female)\n",
    "print(\"Kruskal-Wallis test:\")\n",
    "print(\"  Statistic:\", kruskal_stat)\n",
    "print(\"  p-value:\", kruskal_p_value)\n",
    "\n",
    "# Independent t-test\n",
    "t_stat, t_p_value = stats.ttest_ind(apr_male, apr_female)\n",
    "print(\"\\nIndependent t-test:\")\n",
    "print(\"  Statistic:\", t_stat)\n",
    "print(\"  p-value:\", t_p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44f42f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis test:\n",
      "  Statistic: 204.180642071072\n",
      "  p-value: 2.5560427990712206e-46\n",
      "\n",
      "Independent t-test:\n",
      "  Statistic: 15.296907303573525\n",
      "  p-value: 4.895397221767411e-50\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Kruskal-Wallis test\n",
    "kruskal_stat, kruskal_p_value = stats.kruskal(f1_male, f1_female)\n",
    "print(\"Kruskal-Wallis test:\")\n",
    "print(\"  Statistic:\", kruskal_stat)\n",
    "print(\"  p-value:\", kruskal_p_value)\n",
    "\n",
    "# Independent t-test\n",
    "t_stat, t_p_value = stats.ttest_ind(f1_male, f1_female)\n",
    "print(\"\\nIndependent t-test:\")\n",
    "print(\"  Statistic:\", t_stat)\n",
    "print(\"  p-value:\", t_p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13386f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis test:\n",
      "  Statistic: 951.5657351536727\n",
      "  p-value: 6.058867905842296e-209\n",
      "\n",
      "Independent t-test:\n",
      "  Statistic: 40.513877337497824\n",
      "  p-value: 1.7923794186520421e-262\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Kruskal-Wallis test\n",
    "kruskal_stat, kruskal_p_value = stats.kruskal(acc_male, acc_female)\n",
    "print(\"Kruskal-Wallis test:\")\n",
    "print(\"  Statistic:\", kruskal_stat)\n",
    "print(\"  p-value:\", kruskal_p_value)\n",
    "\n",
    "# Independent t-test\n",
    "t_stat, t_p_value = stats.ttest_ind(acc_male, acc_female)\n",
    "print(\"\\nIndependent t-test:\")\n",
    "print(\"  Statistic:\", t_stat)\n",
    "print(\"  p-value:\", t_p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b276881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0.7466383919640586 0.5470243498933457 0.7678234019501625 0.6629406219367823\\n(0.7171828525946882, 0.776655525633572) (0.4979873922374438, 0.5928792111511485) (0.7410617551462622, 0.7941495124593716) (0.6175962416107382, 0.7026278015945095)\\n\\n0.764761569484173 0.5482275288751095 0.7754524236983841 0.6778789599935521\\n(0.7375531821039054, 0.7919339045209898) (0.5001759634677061, 0.5922628080008435) (0.7495287253141831, 0.7998204667863554) (0.6380562658083903, 0.7137246930784827)\\n\\n0.7462905545013693 0.605554705155347 0.7653867791842476 0.6864282382023428\\n(0.7144760255433712, 0.7782598256501183) (0.5526925644888443, 0.6578182053424811) (0.7355836849507735, 0.7960618846694796) (0.6389986273922029, 0.7307709447415329)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "0.7466383919640586 0.5470243498933457 0.7678234019501625 0.6629406219367823\n",
    "(0.7171828525946882, 0.776655525633572) (0.4979873922374438, 0.5928792111511485) (0.7410617551462622, 0.7941495124593716) (0.6175962416107382, 0.7026278015945095)\n",
    "\n",
    "0.764761569484173 0.5482275288751095 0.7754524236983841 0.6778789599935521\n",
    "(0.7375531821039054, 0.7919339045209898) (0.5001759634677061, 0.5922628080008435) (0.7495287253141831, 0.7998204667863554) (0.6380562658083903, 0.7137246930784827)\n",
    "\n",
    "0.7462905545013693 0.605554705155347 0.7653867791842476 0.6864282382023428\n",
    "(0.7144760255433712, 0.7782598256501183) (0.5526925644888443, 0.6578182053424811) (0.7355836849507735, 0.7960618846694796) (0.6389986273922029, 0.7307709447415329)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5afdd6",
   "metadata": {},
   "source": [
    "# Subgroup Performance: Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de2e8023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2442 893 923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_871515/3927646973.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Age_Group'] = test_df['Age_at_Cath'].apply(map_age_to_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7420528515663946 0.5421483349852821 0.764765980498375 0.657019720442488\n",
      "(0.710537134846387, 0.7732459181343004) (0.4917146161878393, 0.5885634218398414) (0.7356446370530878, 0.7930660888407367) (0.612448111043782, 0.697387040714995)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, age1_test, y_age1, age2_test, y_age2, age3_test, y_age3, age4_test, y_age4 = get_data(agegap=True)\n",
    "\n",
    "'''\n",
    "50 epoch performance\n",
    "'''\n",
    "auc, apr, acc, f1 = do_bootstrap(y_pred, y_test)\n",
    "print(np.mean(auc), np.mean(apr), np.mean(acc), np.mean(f1))\n",
    "print(confidence_interval(auc), confidence_interval(apr), confidence_interval(acc), confidence_interval(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77aeb795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================== Age1 (18 <= age < 35) ==========================\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.6557375688180642 0.31531872176480025 0.6590299277605778 0.4114250171336408\n",
      "(0.286904761904762, 0.9166666666666667) (0.06666666666666667, 0.6666666666666666) (0.4, 0.8666666666666667) (0.0, 0.7938461538461524)\n",
      "========================== Age2 (35 <= age < 50) ==========================\n",
      "4/4 [==============================] - 0s 58ms/step\n",
      "0.7306326548666713 0.5721143619809684 0.7915523809523811 0.6330675336039853\n",
      "(0.6421535440301667, 0.8226086981611695) (0.4239908595016954, 0.7216182249322493) (0.7142857142857143, 0.8666666666666667) (0.4814444444444445, 0.7647549019607843)\n",
      "========================== Age3 (50 <= age < 75) ==========================\n",
      "21/21 [==============================] - 0s 17ms/step\n",
      "0.7488592356617341 0.5170684306259999 0.7923333333333333 0.6425974855004549\n",
      "(0.710632676147382, 0.7861268135024323) (0.452750956995287, 0.5838028749172977) (0.7601246105919003, 0.82398753894081) (0.5857501194457717, 0.6976866263810048)\n",
      "========================== Age4 (75 <= age) ==========================\n",
      "6/6 [==============================] - 0s 24ms/step\n",
      "0.6384239133087056 0.6113348721524209 0.6469316770186335 0.7007633647934853\n",
      "(0.5620680617512763, 0.7093408351168182) (0.5177198820349396, 0.701155352193441) (0.5714285714285714, 0.7204968944099379) (0.6243352542715601, 0.7745250492541514)\n"
     ]
    }
   ],
   "source": [
    "print('========================== Age1 (18 <= age < 35) ==========================')\n",
    "age1_pred = full_model.predict(age1_test)\n",
    "auc_age1, apr_age1, acc_age1, f1_age1 = do_bootstrap(age1_pred, y_age1)\n",
    "print(np.mean(auc_age1), np.mean(apr_age1), np.mean(acc_age1), np.mean(f1_age1))\n",
    "print(confidence_interval(auc_age1), confidence_interval(apr_age1), confidence_interval(acc_age1), confidence_interval(f1_age1))\n",
    "\n",
    "print('========================== Age2 (35 <= age < 50) ==========================')\n",
    "age2_pred = full_model.predict(age2_test)\n",
    "auc_age2, apr_age2, acc_age2, f1_age2 = do_bootstrap(age2_pred, y_age2)\n",
    "print(np.mean(auc_age2), np.mean(apr_age2), np.mean(acc_age2), np.mean(f1_age2))\n",
    "print(confidence_interval(auc_age2), confidence_interval(apr_age2), confidence_interval(acc_age2), confidence_interval(f1_age2))\n",
    "\n",
    "print('========================== Age3 (50 <= age < 75) ==========================')\n",
    "age3_pred = full_model.predict(age3_test)\n",
    "auc_age3, apr_age3, acc_age3, f1_age3 = do_bootstrap(age3_pred, y_age3)\n",
    "print(np.mean(auc_age3), np.mean(apr_age3), np.mean(acc_age3), np.mean(f1_age3))\n",
    "print(confidence_interval(auc_age3), confidence_interval(apr_age3), confidence_interval(acc_age3), confidence_interval(f1_age3))\n",
    "\n",
    "print('========================== Age4 (75 <= age) ==========================')\n",
    "age4_pred = full_model.predict(age4_test)\n",
    "auc_age4, apr_age4, acc_age4, f1_age4 = do_bootstrap(age4_pred, y_age4)\n",
    "print(np.mean(auc_age4), np.mean(apr_age4), np.mean(acc_age4), np.mean(f1_age4))\n",
    "print(confidence_interval(auc_age4), confidence_interval(apr_age4), confidence_interval(acc_age4), confidence_interval(f1_age4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2f11e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis test for AUC: statistics 1403.9363143006196 pvalue 4.121218625370432e-304\n",
      "\n",
      "Independent t-test for AUC: statistics -13.388198473606396 pvalue 3.482888404522028e-39\n",
      "Kruskal-Wallis test for APR: statistics 2213.458261568214 pvalue 0.0\n",
      "\n",
      "One-way ANOVA test for APR: statistics -13.388198473606396 pvalue 3.482888404522028e-39\n"
     ]
    }
   ],
   "source": [
    "def stat_testing(list1, list2, list3=None, list4=None):\n",
    "    if list3 is not None:\n",
    "        kruskal_stat, kruskal_p_value = stats.kruskal(list1, list2, list3, list4)\n",
    "        t_stat, t_p_value = stats.ttest_ind(list1, list2)\n",
    "        return kruskal_stat, kruskal_p_value, t_stat, t_p_value\n",
    "    \n",
    "    else: # age performance gap\n",
    "        kruskal_stat, kruskal_p_value = stats.kruskal(list1, list2, list3, list4)\n",
    "        anova_stat, anova_p_value = f_oneway(list1, list2, list3, list4)\n",
    "        return kruskal_stat, kruskal_p_value, anova_stat, anova_p_value\n",
    "\n",
    "\n",
    "kruskal_stat, kruskal_p_value, anova_stat, anova_p_value = stat_testing(auc_age1, auc_age2, auc_age3, auc_age4)\n",
    "print(\"Kruskal-Wallis test for AUC: statistics {} pvalue {}\".format(kruskal_stat, kruskal_p_value))\n",
    "print(\"\\nIndependent t-test for AUC: statistics {} pvalue {}\".format(anova_stat, anova_p_value))\n",
    "\n",
    "kruskal_stat, kruskal_p_value, t_stat, t_p_value = stat_testing(apr_age1, apr_age2, apr_age3, apr_age4)\n",
    "print(\"Kruskal-Wallis test for APR: statistics {} pvalue {}\".format(kruskal_stat, kruskal_p_value))\n",
    "print(\"\\nOne-way ANOVA test for APR: statistics {} pvalue {}\".format(anova_stat, anova_p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fcc7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/auc.npy', auc)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/apr.npy', apr)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/acc.npy', acc)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/f1.npy', f1)\n",
    "\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/auc_age1.npy', auc_age1)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/apr_age1.npy', apr_age1)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/acc_age1.npy', acc_age1)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/f1_age1.npy', f1_age1)\n",
    "\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/auc_age2.npy', auc_age2)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/apr_age2.npy', apr_age2)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/acc_age2.npy', acc_age2)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/f1_age2.npy', f1_age2)\n",
    "\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/auc_age3.npy', auc_age3)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/apr_age3.npy', apr_age3)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/acc_age3.npy', acc_age3)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/f1_age3.npy', f1_age3)\n",
    "\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/auc_age4.npy', auc_age4)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/apr_age4.npy', apr_age4)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/acc_age4.npy', acc_age4)\n",
    "np.save('/storage/hyewonjeong/metricssl_02/result/pclr/f1_age4.npy', f1_age4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f09bd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Performance Gaps:\n",
      "age1 - age2: {'AUC Gap': 0.07489508604860706, 'APR Gap': 0.2567956402161682}\n",
      "age1 - age3: {'AUC Gap': 0.09312166684366985, 'APR Gap': 0.2017497088611997}\n",
      "age1 - age4: {'AUC Gap': 0.017313655509358594, 'APR Gap': 0.29601615038762064}\n",
      "age2 - age3: {'AUC Gap': 0.018226580795062786, 'APR Gap': 0.05504593135496849}\n",
      "age2 - age4: {'AUC Gap': 0.09220874155796566, 'APR Gap': 0.03922051017145245}\n",
      "age3 - age4: {'AUC Gap': 0.11043532235302844, 'APR Gap': 0.09426644152642094}\n",
      "\n",
      "Average of Pairwise Performance Gaps:\n",
      "AUC Gap: 0.0677\n",
      "APR Gap: 0.1572\n"
     ]
    }
   ],
   "source": [
    "# List of age groups and corresponding lists\n",
    "age_groups = ['age1', 'age2', 'age3', 'age4']\n",
    "auc_lists = [np.mean(auc_age1), np.mean(auc_age2), np.mean(auc_age3), np.mean(auc_age4)]\n",
    "apr_lists = [np.mean(apr_age1), np.mean(apr_age2), np.mean(apr_age3), np.mean(apr_age4)]\n",
    "# rmse_lists = [age1_rmse_list, age2_rmse_list, age3_rmse_list, age4_rmse_list]\n",
    "\n",
    "# Dictionary to store pairwise performance gaps\n",
    "pairwise_gaps = {}\n",
    "\n",
    "# Calculate pairwise performance gaps for auc, apr, and rmse\n",
    "for i in range(len(age_groups)):\n",
    "    for j in range(i+1, len(age_groups)):\n",
    "        gap_auc = abs(auc_lists[i] - auc_lists[j])\n",
    "        gap_apr = abs(apr_lists[i] - apr_lists[j])\n",
    "#         gap_rmse = np.mean(np.abs(np.array(rmse_lists[i]) - np.array(rmse_lists[j])))\n",
    "        key = f\"{age_groups[i]} - {age_groups[j]}\"\n",
    "        pairwise_gaps[key] = {'AUC Gap': gap_auc, 'APR Gap': gap_apr} #, 'RMSE Gap': gap_rmse}\n",
    "\n",
    "# Calculate average of the pairwise performance gaps\n",
    "avg_gap_auc = np.mean([pairwise_gaps[key]['AUC Gap'] for key in pairwise_gaps])\n",
    "avg_gap_apr = np.mean([pairwise_gaps[key]['APR Gap'] for key in pairwise_gaps])\n",
    "# avg_gap_rmse = np.mean([pairwise_gaps[key]['RMSE Gap'] for key in pairwise_gaps])\n",
    "\n",
    "# Print the results\n",
    "print(\"Pairwise Performance Gaps:\")\n",
    "for key, gaps in pairwise_gaps.items():\n",
    "    print(f\"{key}: {gaps}\")\n",
    "\n",
    "print(\"\\nAverage of Pairwise Performance Gaps:\")\n",
    "print(f\"AUC Gap: {avg_gap_auc:.4f}\")\n",
    "print(f\"APR Gap: {avg_gap_apr:.4f}\")\n",
    "# print(f\"RMSE Gap: {avg_gap_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecfa8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pclr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
